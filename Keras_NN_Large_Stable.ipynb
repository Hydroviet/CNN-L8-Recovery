{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import pandas\n",
    "from keras import Sequential\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import keras.callbacks as callbacks\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input1 = Missing image (Masked by cloud)\n",
    "\n",
    "input2 = Referenced images (cloud-free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape=(400,400,1), name='input1')\n",
    "input2 = Input(shape=(400,400,1), name='input2')\n",
    "input3 = Input(shape=(400,400,1), name='input3')\n",
    "\n",
    "conv_1 = Conv2D(30, (3, 3), padding='same')(input1)\n",
    "conv_2 = Conv2D(30, (3, 3), padding='same')(input2)\n",
    "conv_3 = Conv2D(60, (3, 3), padding='same')(input3)\n",
    "\n",
    "concat_1_2 = concatenate([conv_1, conv_2], axis=-1)\n",
    "concat_1_2 = Activation('relu')(concat_1_2)\n",
    "\n",
    "concat_1_2 = Dropout(0.3)(concat_1_2)\n",
    "\n",
    "feature_3 = Conv2D(filters=20, kernel_size=(9, 9),padding='same')(concat_1_2)\n",
    "feature_5 = Conv2D(filters=20, kernel_size=(5, 5),padding='same')(concat_1_2)\n",
    "feature_7 = Conv2D(filters=20, kernel_size=(7, 7),padding='same')(concat_1_2)\n",
    "feature_3_5_7 = concatenate([feature_3, feature_5, feature_7])\n",
    "feature_3_5_7 = Activation('relu')(feature_3_5_7)\n",
    "\n",
    "# feature_3_5_7 = Dropout(0.3)(feature_3_5_7)\n",
    "\n",
    "sum0 = add([concat_1_2, feature_3_5_7])\n",
    "\n",
    "conv1 = Conv2D(filters=60, kernel_size=(3,3), padding='same',activation='relu')(sum0)\n",
    "conv2 = Conv2D(filters=60, kernel_size=(3,3), padding='same',activation='relu')(conv1)\n",
    "\n",
    "sum1 = add([conv2, conv_3])\n",
    "conv3 = Conv2D(filters=60, kernel_size=(3,3), dilation_rate=2, padding='same',activation='relu')(sum1)\n",
    "conv4 = Conv2D(filters=60, kernel_size=(3,3), dilation_rate=3, padding='same',activation='relu')(conv3)\n",
    "conv5 = Conv2D(filters=60, kernel_size=(3,3), dilation_rate=2, padding='same',activation='relu')(conv4)\n",
    "sum2 = add([conv5, conv_3])\n",
    "\n",
    "conv6 = Conv2D(filters=60, kernel_size=(3,3), padding='same',activation='relu')(sum2)\n",
    "\n",
    "conv6 = Dropout(0.3)(conv6)\n",
    "\n",
    "conv6_2 = add([conv6, conv1])\n",
    "\n",
    "conv7 = Conv2D(filters=1, kernel_size=(3,3), padding='same')(conv6_2)\n",
    "\n",
    "model = Model([input1, input2, input3], conv7)\n",
    "\n",
    "model = multi_gpu_model(model, gpus=2, cpu_merge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "nsize = -1\n",
    "\n",
    "f = h5py.File('train1608.hdf5', 'r')\n",
    "trainY = f['label'][:nsize]\n",
    "trainX_1 = f['masked'][:nsize]\n",
    "trainX_2 = f['ref'][:nsize]\n",
    "trainX_3 = f['mask'][:nsize]\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = h5py.File('test1608.hdf5', 'r')\n",
    "testY = f['label'][:]\n",
    "testX_1 = f['masked'][:]\n",
    "testX_2 = f['ref'][:]\n",
    "testX_3 = f['mask'][:]\n",
    "f.close()\n",
    "\n",
    "trainX_3[:,:,:] = (765 - trainX_3[:,:,:])\n",
    "trainX_3[:,:,:] = trainX_3[:,:,:] // 765\n",
    "trainX_3 = abs(trainX_3)\n",
    "\n",
    "testX_3[:,:,:] = (765 - testX_3[:,:,:])\n",
    "testX_3[:,:,:] = testX_3[:,:,:] // 765\n",
    "testX_3 = abs(testX_3)\n",
    "\n",
    "img_rows, img_cols = 400, 400\n",
    "out_rows, out_cols = 400, 400\n",
    "\n",
    "trainX_3 = trainX_1 + np.multiply(trainX_2, np.reshape(trainX_3, (trainX_3.shape[0], img_rows, img_cols, 1)))\n",
    "testX_3 = testX_1 + np.multiply(testX_2, np.reshape(testX_3, (testX_3.shape[0], img_rows, img_cols, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNRLoss(y_true, y_pred):\n",
    "    return -10. * K.log(K.mean(K.square(y_pred - y_true))) / K.log(10.)\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.3\n",
    "    epochs_drop = 50\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 431 samples, validate on 90 samples\n",
      "Epoch 1/200\n",
      "431/431 [==============================] - 130s 302ms/step - loss: 0.0525 - PSNRLoss: 14.1911 - val_loss: 0.0332 - val_PSNRLoss: 15.2503\n",
      "\n",
      "Epoch 00001: val_PSNRLoss improved from -inf to 15.25033, saving model to weight_9_5_7.h5\n",
      "Epoch 2/200\n",
      "431/431 [==============================] - 100s 231ms/step - loss: 0.0184 - PSNRLoss: 17.6674 - val_loss: 0.0252 - val_PSNRLoss: 16.4290\n",
      "\n",
      "Epoch 00002: val_PSNRLoss improved from 15.25033 to 16.42898, saving model to weight_9_5_7.h5\n",
      "Epoch 3/200\n",
      "431/431 [==============================] - 99s 230ms/step - loss: 0.0142 - PSNRLoss: 18.9934 - val_loss: 0.0196 - val_PSNRLoss: 17.5187\n",
      "\n",
      "Epoch 00003: val_PSNRLoss improved from 16.42898 to 17.51874, saving model to weight_9_5_7.h5\n",
      "Epoch 4/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0118 - PSNRLoss: 19.5706 - val_loss: 0.0165 - val_PSNRLoss: 18.2377\n",
      "\n",
      "Epoch 00004: val_PSNRLoss improved from 17.51874 to 18.23770, saving model to weight_9_5_7.h5\n",
      "Epoch 5/200\n",
      "431/431 [==============================] - 97s 226ms/step - loss: 0.0101 - PSNRLoss: 20.3008 - val_loss: 0.0151 - val_PSNRLoss: 18.6354\n",
      "\n",
      "Epoch 00005: val_PSNRLoss improved from 18.23770 to 18.63544, saving model to weight_9_5_7.h5\n",
      "Epoch 6/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0091 - PSNRLoss: 22.2441 - val_loss: 0.0140 - val_PSNRLoss: 18.9653\n",
      "\n",
      "Epoch 00006: val_PSNRLoss improved from 18.63544 to 18.96531, saving model to weight_9_5_7.h5\n",
      "Epoch 7/200\n",
      "431/431 [==============================] - 102s 236ms/step - loss: 0.0082 - PSNRLoss: 21.1049 - val_loss: 0.0129 - val_PSNRLoss: 19.3279\n",
      "\n",
      "Epoch 00007: val_PSNRLoss improved from 18.96531 to 19.32795, saving model to weight_9_5_7.h5\n",
      "Epoch 8/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0075 - PSNRLoss: 21.6169 - val_loss: 0.0118 - val_PSNRLoss: 19.7042\n",
      "\n",
      "Epoch 00008: val_PSNRLoss improved from 19.32795 to 19.70417, saving model to weight_9_5_7.h5\n",
      "Epoch 9/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0069 - PSNRLoss: 22.0183 - val_loss: 0.0110 - val_PSNRLoss: 20.0150\n",
      "\n",
      "Epoch 00009: val_PSNRLoss improved from 19.70417 to 20.01501, saving model to weight_9_5_7.h5\n",
      "Epoch 10/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0064 - PSNRLoss: 22.1055 - val_loss: 0.0103 - val_PSNRLoss: 20.3128\n",
      "\n",
      "Epoch 00010: val_PSNRLoss improved from 20.01501 to 20.31276, saving model to weight_9_5_7.h5\n",
      "Epoch 11/200\n",
      "431/431 [==============================] - 98s 228ms/step - loss: 0.0059 - PSNRLoss: 22.7632 - val_loss: 0.0097 - val_PSNRLoss: 20.5773\n",
      "\n",
      "Epoch 00011: val_PSNRLoss improved from 20.31276 to 20.57726, saving model to weight_9_5_7.h5\n",
      "Epoch 12/200\n",
      "431/431 [==============================] - 102s 236ms/step - loss: 0.0055 - PSNRLoss: 22.9362 - val_loss: 0.0088 - val_PSNRLoss: 20.9677\n",
      "\n",
      "Epoch 00012: val_PSNRLoss improved from 20.57726 to 20.96766, saving model to weight_9_5_7.h5\n",
      "Epoch 13/200\n",
      "431/431 [==============================] - 100s 231ms/step - loss: 0.0051 - PSNRLoss: 23.2408 - val_loss: 0.0083 - val_PSNRLoss: 21.2617\n",
      "\n",
      "Epoch 00013: val_PSNRLoss improved from 20.96766 to 21.26170, saving model to weight_9_5_7.h5\n",
      "Epoch 14/200\n",
      "431/431 [==============================] - 104s 242ms/step - loss: 0.0048 - PSNRLoss: 23.3755 - val_loss: 0.0077 - val_PSNRLoss: 21.5455\n",
      "\n",
      "Epoch 00014: val_PSNRLoss improved from 21.26170 to 21.54545, saving model to weight_9_5_7.h5\n",
      "Epoch 15/200\n",
      "431/431 [==============================] - 99s 231ms/step - loss: 0.0045 - PSNRLoss: 23.6348 - val_loss: 0.0074 - val_PSNRLoss: 21.7125\n",
      "\n",
      "Epoch 00015: val_PSNRLoss improved from 21.54545 to 21.71250, saving model to weight_9_5_7.h5\n",
      "Epoch 16/200\n",
      "431/431 [==============================] - 102s 236ms/step - loss: 0.0043 - PSNRLoss: 23.9728 - val_loss: 0.0071 - val_PSNRLoss: 21.9380\n",
      "\n",
      "Epoch 00016: val_PSNRLoss improved from 21.71250 to 21.93803, saving model to weight_9_5_7.h5\n",
      "Epoch 17/200\n",
      "431/431 [==============================] - 105s 243ms/step - loss: 0.0041 - PSNRLoss: 24.1571 - val_loss: 0.0068 - val_PSNRLoss: 22.0954\n",
      "\n",
      "Epoch 00017: val_PSNRLoss improved from 21.93803 to 22.09539, saving model to weight_9_5_7.h5\n",
      "Epoch 18/200\n",
      "431/431 [==============================] - 98s 227ms/step - loss: 0.0039 - PSNRLoss: 24.2276 - val_loss: 0.0066 - val_PSNRLoss: 22.2061\n",
      "\n",
      "Epoch 00018: val_PSNRLoss improved from 22.09539 to 22.20606, saving model to weight_9_5_7.h5\n",
      "Epoch 19/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0038 - PSNRLoss: 24.4900 - val_loss: 0.0064 - val_PSNRLoss: 22.3458\n",
      "\n",
      "Epoch 00019: val_PSNRLoss improved from 22.20606 to 22.34579, saving model to weight_9_5_7.h5\n",
      "Epoch 20/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0036 - PSNRLoss: 24.6621 - val_loss: 0.0062 - val_PSNRLoss: 22.4790\n",
      "\n",
      "Epoch 00020: val_PSNRLoss improved from 22.34579 to 22.47904, saving model to weight_9_5_7.h5\n",
      "Epoch 21/200\n",
      "431/431 [==============================] - 103s 239ms/step - loss: 0.0035 - PSNRLoss: 25.1668 - val_loss: 0.0061 - val_PSNRLoss: 22.5697\n",
      "\n",
      "Epoch 00021: val_PSNRLoss improved from 22.47904 to 22.56969, saving model to weight_9_5_7.h5\n",
      "Epoch 22/200\n",
      "431/431 [==============================] - 99s 230ms/step - loss: 0.0034 - PSNRLoss: 24.9795 - val_loss: 0.0059 - val_PSNRLoss: 22.6890\n",
      "\n",
      "Epoch 00022: val_PSNRLoss improved from 22.56969 to 22.68902, saving model to weight_9_5_7.h5\n",
      "Epoch 23/200\n",
      "431/431 [==============================] - 99s 230ms/step - loss: 0.0033 - PSNRLoss: 25.1949 - val_loss: 0.0058 - val_PSNRLoss: 22.8191\n",
      "\n",
      "Epoch 00023: val_PSNRLoss improved from 22.68902 to 22.81908, saving model to weight_9_5_7.h5\n",
      "Epoch 24/200\n",
      "431/431 [==============================] - 99s 230ms/step - loss: 0.0032 - PSNRLoss: 25.3213 - val_loss: 0.0056 - val_PSNRLoss: 22.9158\n",
      "\n",
      "Epoch 00024: val_PSNRLoss improved from 22.81908 to 22.91584, saving model to weight_9_5_7.h5\n",
      "Epoch 25/200\n",
      "431/431 [==============================] - 105s 243ms/step - loss: 0.0031 - PSNRLoss: 25.5961 - val_loss: 0.0055 - val_PSNRLoss: 23.0313\n",
      "\n",
      "Epoch 00025: val_PSNRLoss improved from 22.91584 to 23.03128, saving model to weight_9_5_7.h5\n",
      "Epoch 26/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0030 - PSNRLoss: 25.6260 - val_loss: 0.0054 - val_PSNRLoss: 23.0809\n",
      "\n",
      "Epoch 00026: val_PSNRLoss improved from 23.03128 to 23.08089, saving model to weight_9_5_7.h5\n",
      "Epoch 27/200\n",
      "431/431 [==============================] - 101s 234ms/step - loss: 0.0029 - PSNRLoss: 25.5972 - val_loss: 0.0053 - val_PSNRLoss: 23.2197\n",
      "\n",
      "Epoch 00027: val_PSNRLoss improved from 23.08089 to 23.21972, saving model to weight_9_5_7.h5\n",
      "Epoch 28/200\n",
      "431/431 [==============================] - 96s 224ms/step - loss: 0.0029 - PSNRLoss: 26.2420 - val_loss: 0.0052 - val_PSNRLoss: 23.2897\n",
      "\n",
      "Epoch 00028: val_PSNRLoss improved from 23.21972 to 23.28973, saving model to weight_9_5_7.h5\n",
      "Epoch 29/200\n",
      "431/431 [==============================] - 100s 231ms/step - loss: 0.0028 - PSNRLoss: 26.0373 - val_loss: 0.0051 - val_PSNRLoss: 23.3887\n",
      "\n",
      "Epoch 00029: val_PSNRLoss improved from 23.28973 to 23.38872, saving model to weight_9_5_7.h5\n",
      "Epoch 30/200\n",
      "431/431 [==============================] - 98s 228ms/step - loss: 0.0027 - PSNRLoss: 25.7848 - val_loss: 0.0050 - val_PSNRLoss: 23.4209\n",
      "\n",
      "Epoch 00030: val_PSNRLoss improved from 23.38872 to 23.42090, saving model to weight_9_5_7.h5\n",
      "Epoch 31/200\n",
      "431/431 [==============================] - 101s 234ms/step - loss: 0.0027 - PSNRLoss: 25.9131 - val_loss: 0.0050 - val_PSNRLoss: 23.4784\n",
      "\n",
      "Epoch 00031: val_PSNRLoss improved from 23.42090 to 23.47840, saving model to weight_9_5_7.h5\n",
      "Epoch 32/200\n",
      "431/431 [==============================] - 101s 234ms/step - loss: 0.0026 - PSNRLoss: 26.0809 - val_loss: 0.0049 - val_PSNRLoss: 23.5327\n",
      "\n",
      "Epoch 00032: val_PSNRLoss improved from 23.47840 to 23.53271, saving model to weight_9_5_7.h5\n",
      "Epoch 33/200\n",
      "431/431 [==============================] - 102s 236ms/step - loss: 0.0026 - PSNRLoss: 26.0530 - val_loss: 0.0048 - val_PSNRLoss: 23.6017\n",
      "\n",
      "Epoch 00033: val_PSNRLoss improved from 23.53271 to 23.60168, saving model to weight_9_5_7.h5\n",
      "Epoch 34/200\n",
      "431/431 [==============================] - 100s 231ms/step - loss: 0.0026 - PSNRLoss: 26.2245 - val_loss: 0.0047 - val_PSNRLoss: 23.7018\n",
      "\n",
      "Epoch 00034: val_PSNRLoss improved from 23.60168 to 23.70182, saving model to weight_9_5_7.h5\n",
      "Epoch 35/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0025 - PSNRLoss: 26.4816 - val_loss: 0.0047 - val_PSNRLoss: 23.7290\n",
      "\n",
      "Epoch 00035: val_PSNRLoss improved from 23.70182 to 23.72900, saving model to weight_9_5_7.h5\n",
      "Epoch 36/200\n",
      "431/431 [==============================] - 96s 224ms/step - loss: 0.0025 - PSNRLoss: 26.5076 - val_loss: 0.0046 - val_PSNRLoss: 23.7715\n",
      "\n",
      "Epoch 00036: val_PSNRLoss improved from 23.72900 to 23.77148, saving model to weight_9_5_7.h5\n",
      "Epoch 37/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0025 - PSNRLoss: 26.3517 - val_loss: 0.0046 - val_PSNRLoss: 23.8141\n",
      "\n",
      "Epoch 00037: val_PSNRLoss improved from 23.77148 to 23.81415, saving model to weight_9_5_7.h5\n",
      "Epoch 38/200\n",
      "431/431 [==============================] - 99s 231ms/step - loss: 0.0024 - PSNRLoss: 26.3738 - val_loss: 0.0045 - val_PSNRLoss: 23.8564\n",
      "\n",
      "Epoch 00038: val_PSNRLoss improved from 23.81415 to 23.85644, saving model to weight_9_5_7.h5\n",
      "Epoch 39/200\n",
      "431/431 [==============================] - 102s 236ms/step - loss: 0.0024 - PSNRLoss: 26.4759 - val_loss: 0.0045 - val_PSNRLoss: 23.8583\n",
      "\n",
      "Epoch 00039: val_PSNRLoss improved from 23.85644 to 23.85825, saving model to weight_9_5_7.h5\n",
      "Epoch 40/200\n",
      "431/431 [==============================] - 104s 241ms/step - loss: 0.0024 - PSNRLoss: 26.6361 - val_loss: 0.0044 - val_PSNRLoss: 23.9373\n",
      "\n",
      "Epoch 00040: val_PSNRLoss improved from 23.85825 to 23.93726, saving model to weight_9_5_7.h5\n",
      "Epoch 41/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0023 - PSNRLoss: 26.6478 - val_loss: 0.0045 - val_PSNRLoss: 23.9111\n",
      "\n",
      "Epoch 00041: val_PSNRLoss did not improve from 23.93726\n",
      "Epoch 42/200\n",
      "431/431 [==============================] - 102s 236ms/step - loss: 0.0023 - PSNRLoss: 26.6458 - val_loss: 0.0044 - val_PSNRLoss: 24.0079\n",
      "\n",
      "Epoch 00042: val_PSNRLoss improved from 23.93726 to 24.00789, saving model to weight_9_5_7.h5\n",
      "Epoch 43/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0023 - PSNRLoss: 26.6328 - val_loss: 0.0043 - val_PSNRLoss: 24.0325\n",
      "\n",
      "Epoch 00043: val_PSNRLoss improved from 24.00789 to 24.03251, saving model to weight_9_5_7.h5\n",
      "Epoch 44/200\n",
      "431/431 [==============================] - 98s 226ms/step - loss: 0.0023 - PSNRLoss: 26.7289 - val_loss: 0.0044 - val_PSNRLoss: 24.0130\n",
      "\n",
      "Epoch 00044: val_PSNRLoss did not improve from 24.03251\n",
      "Epoch 45/200\n",
      "431/431 [==============================] - 97s 225ms/step - loss: 0.0022 - PSNRLoss: 26.9315 - val_loss: 0.0043 - val_PSNRLoss: 24.0277\n",
      "\n",
      "Epoch 00045: val_PSNRLoss did not improve from 24.03251\n",
      "Epoch 46/200\n",
      "431/431 [==============================] - 98s 228ms/step - loss: 0.0022 - PSNRLoss: 26.9303 - val_loss: 0.0043 - val_PSNRLoss: 24.1070\n",
      "\n",
      "Epoch 00046: val_PSNRLoss improved from 24.03251 to 24.10696, saving model to weight_9_5_7.h5\n",
      "Epoch 47/200\n",
      "431/431 [==============================] - 104s 241ms/step - loss: 0.0022 - PSNRLoss: 26.8244 - val_loss: 0.0043 - val_PSNRLoss: 24.1108\n",
      "\n",
      "Epoch 00047: val_PSNRLoss improved from 24.10696 to 24.11078, saving model to weight_9_5_7.h5\n",
      "Epoch 48/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0022 - PSNRLoss: 27.0690 - val_loss: 0.0042 - val_PSNRLoss: 24.2183\n",
      "\n",
      "Epoch 00048: val_PSNRLoss improved from 24.11078 to 24.21829, saving model to weight_9_5_7.h5\n",
      "Epoch 49/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0021 - PSNRLoss: 27.0352 - val_loss: 0.0042 - val_PSNRLoss: 24.2237\n",
      "\n",
      "Epoch 00049: val_PSNRLoss improved from 24.21829 to 24.22367, saving model to weight_9_5_7.h5\n",
      "Epoch 50/200\n",
      "431/431 [==============================] - 102s 236ms/step - loss: 0.0021 - PSNRLoss: 27.0346 - val_loss: 0.0041 - val_PSNRLoss: 24.2922\n",
      "\n",
      "Epoch 00050: val_PSNRLoss improved from 24.22367 to 24.29219, saving model to weight_9_5_7.h5\n",
      "Epoch 51/200\n",
      "431/431 [==============================] - 105s 244ms/step - loss: 0.0021 - PSNRLoss: 27.2095 - val_loss: 0.0041 - val_PSNRLoss: 24.2916\n",
      "\n",
      "Epoch 00051: val_PSNRLoss did not improve from 24.29219\n",
      "Epoch 52/200\n",
      "431/431 [==============================] - 103s 239ms/step - loss: 0.0021 - PSNRLoss: 27.0897 - val_loss: 0.0041 - val_PSNRLoss: 24.3175\n",
      "\n",
      "Epoch 00052: val_PSNRLoss improved from 24.29219 to 24.31749, saving model to weight_9_5_7.h5\n",
      "Epoch 53/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0021 - PSNRLoss: 27.1865 - val_loss: 0.0040 - val_PSNRLoss: 24.3319\n",
      "\n",
      "Epoch 00053: val_PSNRLoss improved from 24.31749 to 24.33191, saving model to weight_9_5_7.h5\n",
      "Epoch 54/200\n",
      "431/431 [==============================] - 98s 228ms/step - loss: 0.0020 - PSNRLoss: 27.1426 - val_loss: 0.0040 - val_PSNRLoss: 24.3632\n",
      "\n",
      "Epoch 00054: val_PSNRLoss improved from 24.33191 to 24.36323, saving model to weight_9_5_7.h5\n",
      "Epoch 55/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0020 - PSNRLoss: 27.4042 - val_loss: 0.0040 - val_PSNRLoss: 24.3412\n",
      "\n",
      "Epoch 00055: val_PSNRLoss did not improve from 24.36323\n",
      "Epoch 56/200\n",
      "431/431 [==============================] - 96s 224ms/step - loss: 0.0020 - PSNRLoss: 27.2862 - val_loss: 0.0040 - val_PSNRLoss: 24.3267\n",
      "\n",
      "Epoch 00056: val_PSNRLoss did not improve from 24.36323\n",
      "Epoch 57/200\n",
      "431/431 [==============================] - 104s 241ms/step - loss: 0.0020 - PSNRLoss: 27.5087 - val_loss: 0.0040 - val_PSNRLoss: 24.3651\n",
      "\n",
      "Epoch 00057: val_PSNRLoss improved from 24.36323 to 24.36507, saving model to weight_9_5_7.h5\n",
      "Epoch 58/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0020 - PSNRLoss: 27.2890 - val_loss: 0.0040 - val_PSNRLoss: 24.3838\n",
      "\n",
      "Epoch 00058: val_PSNRLoss improved from 24.36507 to 24.38379, saving model to weight_9_5_7.h5\n",
      "Epoch 59/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0020 - PSNRLoss: 27.5280 - val_loss: 0.0039 - val_PSNRLoss: 24.4877\n",
      "\n",
      "Epoch 00059: val_PSNRLoss improved from 24.38379 to 24.48773, saving model to weight_9_5_7.h5\n",
      "Epoch 60/200\n",
      "431/431 [==============================] - 101s 233ms/step - loss: 0.0019 - PSNRLoss: 27.6125 - val_loss: 0.0039 - val_PSNRLoss: 24.5061\n",
      "\n",
      "Epoch 00060: val_PSNRLoss improved from 24.48773 to 24.50612, saving model to weight_9_5_7.h5\n",
      "Epoch 61/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0019 - PSNRLoss: 27.4973 - val_loss: 0.0039 - val_PSNRLoss: 24.4855\n",
      "\n",
      "Epoch 00061: val_PSNRLoss did not improve from 24.50612\n",
      "Epoch 62/200\n",
      "431/431 [==============================] - 104s 240ms/step - loss: 0.0019 - PSNRLoss: 27.4516 - val_loss: 0.0039 - val_PSNRLoss: 24.5200\n",
      "\n",
      "Epoch 00062: val_PSNRLoss improved from 24.50612 to 24.52002, saving model to weight_9_5_7.h5\n",
      "Epoch 63/200\n",
      "431/431 [==============================] - 104s 241ms/step - loss: 0.0019 - PSNRLoss: 27.8014 - val_loss: 0.0038 - val_PSNRLoss: 24.5608\n",
      "\n",
      "Epoch 00063: val_PSNRLoss improved from 24.52002 to 24.56081, saving model to weight_9_5_7.h5\n",
      "Epoch 64/200\n",
      "431/431 [==============================] - 101s 233ms/step - loss: 0.0019 - PSNRLoss: 27.6757 - val_loss: 0.0038 - val_PSNRLoss: 24.5406\n",
      "\n",
      "Epoch 00064: val_PSNRLoss did not improve from 24.56081\n",
      "Epoch 65/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0019 - PSNRLoss: 27.7848 - val_loss: 0.0038 - val_PSNRLoss: 24.5981\n",
      "\n",
      "Epoch 00065: val_PSNRLoss improved from 24.56081 to 24.59812, saving model to weight_9_5_7.h5\n",
      "Epoch 66/200\n",
      "431/431 [==============================] - 99s 229ms/step - loss: 0.0019 - PSNRLoss: 27.5312 - val_loss: 0.0038 - val_PSNRLoss: 24.6463\n",
      "\n",
      "Epoch 00066: val_PSNRLoss improved from 24.59812 to 24.64635, saving model to weight_9_5_7.h5\n",
      "Epoch 67/200\n",
      "431/431 [==============================] - 104s 240ms/step - loss: 0.0018 - PSNRLoss: 27.6858 - val_loss: 0.0038 - val_PSNRLoss: 24.6195\n",
      "\n",
      "Epoch 00067: val_PSNRLoss did not improve from 24.64635\n",
      "Epoch 68/200\n",
      "431/431 [==============================] - 103s 239ms/step - loss: 0.0018 - PSNRLoss: 27.6777 - val_loss: 0.0037 - val_PSNRLoss: 24.6889\n",
      "\n",
      "Epoch 00068: val_PSNRLoss improved from 24.64635 to 24.68894, saving model to weight_9_5_7.h5\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431/431 [==============================] - 104s 241ms/step - loss: 0.0018 - PSNRLoss: 27.7387 - val_loss: 0.0037 - val_PSNRLoss: 24.6613\n",
      "\n",
      "Epoch 00069: val_PSNRLoss did not improve from 24.68894\n",
      "Epoch 70/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0018 - PSNRLoss: 27.6381 - val_loss: 0.0037 - val_PSNRLoss: 24.6898\n",
      "\n",
      "Epoch 00070: val_PSNRLoss improved from 24.68894 to 24.68979, saving model to weight_9_5_7.h5\n",
      "Epoch 71/200\n",
      "431/431 [==============================] - 96s 223ms/step - loss: 0.0018 - PSNRLoss: 27.8855 - val_loss: 0.0037 - val_PSNRLoss: 24.7036\n",
      "\n",
      "Epoch 00071: val_PSNRLoss improved from 24.68979 to 24.70357, saving model to weight_9_5_7.h5\n",
      "Epoch 72/200\n",
      "431/431 [==============================] - 104s 241ms/step - loss: 0.0018 - PSNRLoss: 27.8508 - val_loss: 0.0037 - val_PSNRLoss: 24.7085\n",
      "\n",
      "Epoch 00072: val_PSNRLoss improved from 24.70357 to 24.70853, saving model to weight_9_5_7.h5\n",
      "Epoch 73/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0018 - PSNRLoss: 27.8731 - val_loss: 0.0036 - val_PSNRLoss: 24.7875\n",
      "\n",
      "Epoch 00073: val_PSNRLoss improved from 24.70853 to 24.78752, saving model to weight_9_5_7.h5\n",
      "Epoch 74/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0018 - PSNRLoss: 27.7628 - val_loss: 0.0037 - val_PSNRLoss: 24.7599\n",
      "\n",
      "Epoch 00074: val_PSNRLoss did not improve from 24.78752\n",
      "Epoch 75/200\n",
      "431/431 [==============================] - 97s 226ms/step - loss: 0.0017 - PSNRLoss: 27.9634 - val_loss: 0.0036 - val_PSNRLoss: 24.7750\n",
      "\n",
      "Epoch 00075: val_PSNRLoss did not improve from 24.78752\n",
      "Epoch 76/200\n",
      "431/431 [==============================] - 101s 233ms/step - loss: 0.0017 - PSNRLoss: 28.0238 - val_loss: 0.0036 - val_PSNRLoss: 24.7919\n",
      "\n",
      "Epoch 00076: val_PSNRLoss improved from 24.78752 to 24.79194, saving model to weight_9_5_7.h5\n",
      "Epoch 77/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0017 - PSNRLoss: 28.2288 - val_loss: 0.0036 - val_PSNRLoss: 24.8638\n",
      "\n",
      "Epoch 00077: val_PSNRLoss improved from 24.79194 to 24.86377, saving model to weight_9_5_7.h5\n",
      "Epoch 78/200\n",
      "431/431 [==============================] - 99s 229ms/step - loss: 0.0017 - PSNRLoss: 27.9481 - val_loss: 0.0036 - val_PSNRLoss: 24.8520\n",
      "\n",
      "Epoch 00078: val_PSNRLoss did not improve from 24.86377\n",
      "Epoch 79/200\n",
      "431/431 [==============================] - 96s 222ms/step - loss: 0.0017 - PSNRLoss: 28.0955 - val_loss: 0.0036 - val_PSNRLoss: 24.8026\n",
      "\n",
      "Epoch 00079: val_PSNRLoss did not improve from 24.86377\n",
      "Epoch 80/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0017 - PSNRLoss: 28.0383 - val_loss: 0.0036 - val_PSNRLoss: 24.8531\n",
      "\n",
      "Epoch 00080: val_PSNRLoss did not improve from 24.86377\n",
      "Epoch 81/200\n",
      "431/431 [==============================] - 101s 233ms/step - loss: 0.0017 - PSNRLoss: 28.0364 - val_loss: 0.0036 - val_PSNRLoss: 24.8577\n",
      "\n",
      "Epoch 00081: val_PSNRLoss did not improve from 24.86377\n",
      "Epoch 82/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0017 - PSNRLoss: 28.0381 - val_loss: 0.0036 - val_PSNRLoss: 24.8010\n",
      "\n",
      "Epoch 00082: val_PSNRLoss did not improve from 24.86377\n",
      "Epoch 83/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0017 - PSNRLoss: 28.0879 - val_loss: 0.0036 - val_PSNRLoss: 24.8501\n",
      "\n",
      "Epoch 00083: val_PSNRLoss did not improve from 24.86377\n",
      "Epoch 84/200\n",
      "431/431 [==============================] - 105s 245ms/step - loss: 0.0017 - PSNRLoss: 28.0371 - val_loss: 0.0036 - val_PSNRLoss: 24.8184\n",
      "\n",
      "Epoch 00084: val_PSNRLoss did not improve from 24.86377\n",
      "Epoch 85/200\n",
      "431/431 [==============================] - 104s 242ms/step - loss: 0.0016 - PSNRLoss: 28.2310 - val_loss: 0.0035 - val_PSNRLoss: 24.9293\n",
      "\n",
      "Epoch 00085: val_PSNRLoss improved from 24.86377 to 24.92934, saving model to weight_9_5_7.h5\n",
      "Epoch 86/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0016 - PSNRLoss: 28.3621 - val_loss: 0.0035 - val_PSNRLoss: 24.9333\n",
      "\n",
      "Epoch 00086: val_PSNRLoss improved from 24.92934 to 24.93335, saving model to weight_9_5_7.h5\n",
      "Epoch 87/200\n",
      "431/431 [==============================] - 99s 229ms/step - loss: 0.0016 - PSNRLoss: 28.3248 - val_loss: 0.0036 - val_PSNRLoss: 24.8474\n",
      "\n",
      "Epoch 00087: val_PSNRLoss did not improve from 24.93335\n",
      "Epoch 88/200\n",
      "431/431 [==============================] - 101s 233ms/step - loss: 0.0016 - PSNRLoss: 28.3308 - val_loss: 0.0035 - val_PSNRLoss: 24.9248\n",
      "\n",
      "Epoch 00088: val_PSNRLoss did not improve from 24.93335\n",
      "Epoch 89/200\n",
      "431/431 [==============================] - 102s 236ms/step - loss: 0.0016 - PSNRLoss: 28.5001 - val_loss: 0.0035 - val_PSNRLoss: 24.9655\n",
      "\n",
      "Epoch 00089: val_PSNRLoss improved from 24.93335 to 24.96551, saving model to weight_9_5_7.h5\n",
      "Epoch 90/200\n",
      "431/431 [==============================] - 97s 226ms/step - loss: 0.0016 - PSNRLoss: 28.3209 - val_loss: 0.0034 - val_PSNRLoss: 25.0179\n",
      "\n",
      "Epoch 00090: val_PSNRLoss improved from 24.96551 to 25.01790, saving model to weight_9_5_7.h5\n",
      "Epoch 91/200\n",
      "431/431 [==============================] - 98s 228ms/step - loss: 0.0016 - PSNRLoss: 28.2609 - val_loss: 0.0035 - val_PSNRLoss: 24.9548\n",
      "\n",
      "Epoch 00091: val_PSNRLoss did not improve from 25.01790\n",
      "Epoch 92/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0016 - PSNRLoss: 28.2089 - val_loss: 0.0034 - val_PSNRLoss: 25.0345\n",
      "\n",
      "Epoch 00092: val_PSNRLoss improved from 25.01790 to 25.03446, saving model to weight_9_5_7.h5\n",
      "Epoch 93/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0016 - PSNRLoss: 28.5270 - val_loss: 0.0034 - val_PSNRLoss: 25.0339\n",
      "\n",
      "Epoch 00093: val_PSNRLoss did not improve from 25.03446\n",
      "Epoch 94/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0016 - PSNRLoss: 28.3717 - val_loss: 0.0034 - val_PSNRLoss: 25.0416\n",
      "\n",
      "Epoch 00094: val_PSNRLoss improved from 25.03446 to 25.04155, saving model to weight_9_5_7.h5\n",
      "Epoch 95/200\n",
      "431/431 [==============================] - 103s 240ms/step - loss: 0.0016 - PSNRLoss: 28.4640 - val_loss: 0.0034 - val_PSNRLoss: 25.0129\n",
      "\n",
      "Epoch 00095: val_PSNRLoss did not improve from 25.04155\n",
      "Epoch 96/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0015 - PSNRLoss: 28.6655 - val_loss: 0.0034 - val_PSNRLoss: 25.0032\n",
      "\n",
      "Epoch 00096: val_PSNRLoss did not improve from 25.04155\n",
      "Epoch 97/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0015 - PSNRLoss: 28.4854 - val_loss: 0.0034 - val_PSNRLoss: 25.0224\n",
      "\n",
      "Epoch 00097: val_PSNRLoss did not improve from 25.04155\n",
      "Epoch 98/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0015 - PSNRLoss: 28.5370 - val_loss: 0.0034 - val_PSNRLoss: 25.0925\n",
      "\n",
      "Epoch 00098: val_PSNRLoss improved from 25.04155 to 25.09252, saving model to weight_9_5_7.h5\n",
      "Epoch 99/200\n",
      "431/431 [==============================] - 105s 243ms/step - loss: 0.0015 - PSNRLoss: 28.5118 - val_loss: 0.0034 - val_PSNRLoss: 25.0541\n",
      "\n",
      "Epoch 00099: val_PSNRLoss did not improve from 25.09252\n",
      "Epoch 100/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0015 - PSNRLoss: 28.9649 - val_loss: 0.0034 - val_PSNRLoss: 25.0909\n",
      "\n",
      "Epoch 00100: val_PSNRLoss did not improve from 25.09252\n",
      "Epoch 101/200\n",
      "431/431 [==============================] - 101s 234ms/step - loss: 0.0015 - PSNRLoss: 28.5757 - val_loss: 0.0036 - val_PSNRLoss: 24.7652\n",
      "\n",
      "Epoch 00101: val_PSNRLoss did not improve from 25.09252\n",
      "Epoch 102/200\n",
      "431/431 [==============================] - 97s 225ms/step - loss: 0.0015 - PSNRLoss: 28.4805 - val_loss: 0.0033 - val_PSNRLoss: 25.1454\n",
      "\n",
      "Epoch 00102: val_PSNRLoss improved from 25.09252 to 25.14535, saving model to weight_9_5_7.h5\n",
      "Epoch 103/200\n",
      "431/431 [==============================] - 101s 234ms/step - loss: 0.0015 - PSNRLoss: 28.4958 - val_loss: 0.0033 - val_PSNRLoss: 25.1390\n",
      "\n",
      "Epoch 00103: val_PSNRLoss did not improve from 25.14535\n",
      "Epoch 104/200\n",
      "431/431 [==============================] - 102s 236ms/step - loss: 0.0015 - PSNRLoss: 28.4882 - val_loss: 0.0033 - val_PSNRLoss: 25.1938\n",
      "\n",
      "Epoch 00104: val_PSNRLoss improved from 25.14535 to 25.19385, saving model to weight_9_5_7.h5\n",
      "Epoch 105/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0015 - PSNRLoss: 28.5696 - val_loss: 0.0033 - val_PSNRLoss: 25.1838\n",
      "\n",
      "Epoch 00105: val_PSNRLoss did not improve from 25.19385\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431/431 [==============================] - 104s 242ms/step - loss: 0.0015 - PSNRLoss: 28.6379 - val_loss: 0.0033 - val_PSNRLoss: 25.1918\n",
      "\n",
      "Epoch 00106: val_PSNRLoss did not improve from 25.19385\n",
      "Epoch 107/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0015 - PSNRLoss: 28.5063 - val_loss: 0.0033 - val_PSNRLoss: 25.1337\n",
      "\n",
      "Epoch 00107: val_PSNRLoss did not improve from 25.19385\n",
      "Epoch 108/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0015 - PSNRLoss: 28.6357 - val_loss: 0.0033 - val_PSNRLoss: 25.2101\n",
      "\n",
      "Epoch 00108: val_PSNRLoss improved from 25.19385 to 25.21006, saving model to weight_9_5_7.h5\n",
      "Epoch 109/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0015 - PSNRLoss: 28.8695 - val_loss: 0.0033 - val_PSNRLoss: 25.2176\n",
      "\n",
      "Epoch 00109: val_PSNRLoss improved from 25.21006 to 25.21765, saving model to weight_9_5_7.h5\n",
      "Epoch 110/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0015 - PSNRLoss: 28.6692 - val_loss: 0.0033 - val_PSNRLoss: 25.2397\n",
      "\n",
      "Epoch 00110: val_PSNRLoss improved from 25.21765 to 25.23967, saving model to weight_9_5_7.h5\n",
      "Epoch 111/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0014 - PSNRLoss: 28.6863 - val_loss: 0.0033 - val_PSNRLoss: 25.2376\n",
      "\n",
      "Epoch 00111: val_PSNRLoss did not improve from 25.23967\n",
      "Epoch 112/200\n",
      "431/431 [==============================] - 100s 231ms/step - loss: 0.0014 - PSNRLoss: 28.7382 - val_loss: 0.0032 - val_PSNRLoss: 25.2725\n",
      "\n",
      "Epoch 00112: val_PSNRLoss improved from 25.23967 to 25.27248, saving model to weight_9_5_7.h5\n",
      "Epoch 113/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0014 - PSNRLoss: 28.5941 - val_loss: 0.0032 - val_PSNRLoss: 25.2684\n",
      "\n",
      "Epoch 00113: val_PSNRLoss did not improve from 25.27248\n",
      "Epoch 114/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0014 - PSNRLoss: 28.7021 - val_loss: 0.0033 - val_PSNRLoss: 25.2553\n",
      "\n",
      "Epoch 00114: val_PSNRLoss did not improve from 25.27248\n",
      "Epoch 115/200\n",
      "431/431 [==============================] - 99s 229ms/step - loss: 0.0014 - PSNRLoss: 28.6236 - val_loss: 0.0032 - val_PSNRLoss: 25.2845\n",
      "\n",
      "Epoch 00115: val_PSNRLoss improved from 25.27248 to 25.28445, saving model to weight_9_5_7.h5\n",
      "Epoch 116/200\n",
      "431/431 [==============================] - 99s 230ms/step - loss: 0.0014 - PSNRLoss: 28.9197 - val_loss: 0.0033 - val_PSNRLoss: 25.2410\n",
      "\n",
      "Epoch 00116: val_PSNRLoss did not improve from 25.28445\n",
      "Epoch 117/200\n",
      "431/431 [==============================] - 102s 238ms/step - loss: 0.0014 - PSNRLoss: 28.8985 - val_loss: 0.0033 - val_PSNRLoss: 25.1337\n",
      "\n",
      "Epoch 00117: val_PSNRLoss did not improve from 25.28445\n",
      "Epoch 118/200\n",
      "431/431 [==============================] - 105s 243ms/step - loss: 0.0014 - PSNRLoss: 28.9306 - val_loss: 0.0032 - val_PSNRLoss: 25.3063\n",
      "\n",
      "Epoch 00118: val_PSNRLoss improved from 25.28445 to 25.30630, saving model to weight_9_5_7.h5\n",
      "Epoch 119/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0014 - PSNRLoss: 29.1389 - val_loss: 0.0032 - val_PSNRLoss: 25.2845\n",
      "\n",
      "Epoch 00119: val_PSNRLoss did not improve from 25.30630\n",
      "Epoch 120/200\n",
      "431/431 [==============================] - 106s 246ms/step - loss: 0.0014 - PSNRLoss: 28.9033 - val_loss: 0.0032 - val_PSNRLoss: 25.2963\n",
      "\n",
      "Epoch 00120: val_PSNRLoss did not improve from 25.30630\n",
      "Epoch 121/200\n",
      "431/431 [==============================] - 100s 231ms/step - loss: 0.0014 - PSNRLoss: 28.9778 - val_loss: 0.0032 - val_PSNRLoss: 25.3005\n",
      "\n",
      "Epoch 00121: val_PSNRLoss did not improve from 25.30630\n",
      "Epoch 122/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0014 - PSNRLoss: 28.8523 - val_loss: 0.0032 - val_PSNRLoss: 25.3126\n",
      "\n",
      "Epoch 00122: val_PSNRLoss improved from 25.30630 to 25.31256, saving model to weight_9_5_7.h5\n",
      "Epoch 123/200\n",
      "431/431 [==============================] - 97s 226ms/step - loss: 0.0014 - PSNRLoss: 28.9765 - val_loss: 0.0032 - val_PSNRLoss: 25.2949\n",
      "\n",
      "Epoch 00123: val_PSNRLoss did not improve from 25.31256\n",
      "Epoch 124/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0014 - PSNRLoss: 28.9734 - val_loss: 0.0032 - val_PSNRLoss: 25.3702\n",
      "\n",
      "Epoch 00124: val_PSNRLoss improved from 25.31256 to 25.37016, saving model to weight_9_5_7.h5\n",
      "Epoch 125/200\n",
      "431/431 [==============================] - 99s 229ms/step - loss: 0.0014 - PSNRLoss: 29.0251 - val_loss: 0.0032 - val_PSNRLoss: 25.3714\n",
      "\n",
      "Epoch 00125: val_PSNRLoss improved from 25.37016 to 25.37142, saving model to weight_9_5_7.h5\n",
      "Epoch 126/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0014 - PSNRLoss: 29.0845 - val_loss: 0.0032 - val_PSNRLoss: 25.3521\n",
      "\n",
      "Epoch 00126: val_PSNRLoss did not improve from 25.37142\n",
      "Epoch 127/200\n",
      "431/431 [==============================] - 103s 239ms/step - loss: 0.0014 - PSNRLoss: 28.9187 - val_loss: 0.0032 - val_PSNRLoss: 25.2819\n",
      "\n",
      "Epoch 00127: val_PSNRLoss did not improve from 25.37142\n",
      "Epoch 128/200\n",
      "431/431 [==============================] - 102s 238ms/step - loss: 0.0014 - PSNRLoss: 28.9528 - val_loss: 0.0031 - val_PSNRLoss: 25.4044\n",
      "\n",
      "Epoch 00128: val_PSNRLoss improved from 25.37142 to 25.40437, saving model to weight_9_5_7.h5\n",
      "Epoch 129/200\n",
      "431/431 [==============================] - 101s 234ms/step - loss: 0.0014 - PSNRLoss: 29.1092 - val_loss: 0.0031 - val_PSNRLoss: 25.3860\n",
      "\n",
      "Epoch 00129: val_PSNRLoss did not improve from 25.40437\n",
      "Epoch 130/200\n",
      "431/431 [==============================] - 98s 227ms/step - loss: 0.0014 - PSNRLoss: 29.1116 - val_loss: 0.0032 - val_PSNRLoss: 25.3623\n",
      "\n",
      "Epoch 00130: val_PSNRLoss did not improve from 25.40437\n",
      "Epoch 131/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0013 - PSNRLoss: 28.9888 - val_loss: 0.0031 - val_PSNRLoss: 25.4535\n",
      "\n",
      "Epoch 00131: val_PSNRLoss improved from 25.40437 to 25.45348, saving model to weight_9_5_7.h5\n",
      "Epoch 132/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0013 - PSNRLoss: 29.1026 - val_loss: 0.0031 - val_PSNRLoss: 25.4490\n",
      "\n",
      "Epoch 00132: val_PSNRLoss did not improve from 25.45348\n",
      "Epoch 133/200\n",
      "431/431 [==============================] - 102s 236ms/step - loss: 0.0013 - PSNRLoss: 29.2082 - val_loss: 0.0031 - val_PSNRLoss: 25.4322\n",
      "\n",
      "Epoch 00133: val_PSNRLoss did not improve from 25.45348\n",
      "Epoch 134/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0013 - PSNRLoss: 29.1855 - val_loss: 0.0031 - val_PSNRLoss: 25.4870\n",
      "\n",
      "Epoch 00134: val_PSNRLoss improved from 25.45348 to 25.48701, saving model to weight_9_5_7.h5\n",
      "Epoch 135/200\n",
      "431/431 [==============================] - 99s 229ms/step - loss: 0.0013 - PSNRLoss: 29.1905 - val_loss: 0.0031 - val_PSNRLoss: 25.4064\n",
      "\n",
      "Epoch 00135: val_PSNRLoss did not improve from 25.48701\n",
      "Epoch 136/200\n",
      "431/431 [==============================] - 103s 239ms/step - loss: 0.0013 - PSNRLoss: 29.1990 - val_loss: 0.0032 - val_PSNRLoss: 25.3290\n",
      "\n",
      "Epoch 00136: val_PSNRLoss did not improve from 25.48701\n",
      "Epoch 137/200\n",
      "431/431 [==============================] - 99s 229ms/step - loss: 0.0013 - PSNRLoss: 29.1457 - val_loss: 0.0031 - val_PSNRLoss: 25.5109\n",
      "\n",
      "Epoch 00137: val_PSNRLoss improved from 25.48701 to 25.51094, saving model to weight_9_5_7.h5\n",
      "Epoch 138/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0013 - PSNRLoss: 29.0376 - val_loss: 0.0031 - val_PSNRLoss: 25.5089\n",
      "\n",
      "Epoch 00138: val_PSNRLoss did not improve from 25.51094\n",
      "Epoch 139/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0013 - PSNRLoss: 29.1497 - val_loss: 0.0031 - val_PSNRLoss: 25.5184\n",
      "\n",
      "Epoch 00139: val_PSNRLoss improved from 25.51094 to 25.51836, saving model to weight_9_5_7.h5\n",
      "Epoch 140/200\n",
      "431/431 [==============================] - 99s 230ms/step - loss: 0.0013 - PSNRLoss: 29.2619 - val_loss: 0.0030 - val_PSNRLoss: 25.5397\n",
      "\n",
      "Epoch 00140: val_PSNRLoss improved from 25.51836 to 25.53971, saving model to weight_9_5_7.h5\n",
      "Epoch 141/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0013 - PSNRLoss: 29.3504 - val_loss: 0.0030 - val_PSNRLoss: 25.5581\n",
      "\n",
      "Epoch 00141: val_PSNRLoss improved from 25.53971 to 25.55814, saving model to weight_9_5_7.h5\n",
      "Epoch 142/200\n",
      "431/431 [==============================] - 106s 245ms/step - loss: 0.0013 - PSNRLoss: 29.3772 - val_loss: 0.0030 - val_PSNRLoss: 25.5796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00142: val_PSNRLoss improved from 25.55814 to 25.57959, saving model to weight_9_5_7.h5\n",
      "Epoch 143/200\n",
      "431/431 [==============================] - 105s 243ms/step - loss: 0.0013 - PSNRLoss: 29.3611 - val_loss: 0.0030 - val_PSNRLoss: 25.5875\n",
      "\n",
      "Epoch 00143: val_PSNRLoss improved from 25.57959 to 25.58746, saving model to weight_9_5_7.h5\n",
      "Epoch 144/200\n",
      "431/431 [==============================] - 100s 231ms/step - loss: 0.0013 - PSNRLoss: 29.2751 - val_loss: 0.0031 - val_PSNRLoss: 25.5321\n",
      "\n",
      "Epoch 00144: val_PSNRLoss did not improve from 25.58746\n",
      "Epoch 145/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0013 - PSNRLoss: 29.5879 - val_loss: 0.0032 - val_PSNRLoss: 25.3207\n",
      "\n",
      "Epoch 00145: val_PSNRLoss did not improve from 25.58746\n",
      "Epoch 146/200\n",
      "431/431 [==============================] - 101s 233ms/step - loss: 0.0013 - PSNRLoss: 29.2337 - val_loss: 0.0030 - val_PSNRLoss: 25.5672\n",
      "\n",
      "Epoch 00146: val_PSNRLoss did not improve from 25.58746\n",
      "Epoch 147/200\n",
      "431/431 [==============================] - 98s 226ms/step - loss: 0.0013 - PSNRLoss: 29.3102 - val_loss: 0.0030 - val_PSNRLoss: 25.5933\n",
      "\n",
      "Epoch 00147: val_PSNRLoss improved from 25.58746 to 25.59326, saving model to weight_9_5_7.h5\n",
      "Epoch 148/200\n",
      "431/431 [==============================] - 104s 242ms/step - loss: 0.0013 - PSNRLoss: 29.3447 - val_loss: 0.0030 - val_PSNRLoss: 25.6100\n",
      "\n",
      "Epoch 00148: val_PSNRLoss improved from 25.59326 to 25.61001, saving model to weight_9_5_7.h5\n",
      "Epoch 149/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0013 - PSNRLoss: 29.4248 - val_loss: 0.0030 - val_PSNRLoss: 25.5875\n",
      "\n",
      "Epoch 00149: val_PSNRLoss did not improve from 25.61001\n",
      "Epoch 150/200\n",
      "431/431 [==============================] - 104s 242ms/step - loss: 0.0013 - PSNRLoss: 29.3864 - val_loss: 0.0030 - val_PSNRLoss: 25.6215\n",
      "\n",
      "Epoch 00150: val_PSNRLoss improved from 25.61001 to 25.62146, saving model to weight_9_5_7.h5\n",
      "Epoch 151/200\n",
      "431/431 [==============================] - 99s 231ms/step - loss: 0.0013 - PSNRLoss: 29.9763 - val_loss: 0.0030 - val_PSNRLoss: 25.6088\n",
      "\n",
      "Epoch 00151: val_PSNRLoss did not improve from 25.62146\n",
      "Epoch 152/200\n",
      "431/431 [==============================] - 101s 235ms/step - loss: 0.0012 - PSNRLoss: 29.4453 - val_loss: 0.0030 - val_PSNRLoss: 25.6344\n",
      "\n",
      "Epoch 00152: val_PSNRLoss improved from 25.62146 to 25.63435, saving model to weight_9_5_7.h5\n",
      "Epoch 153/200\n",
      "431/431 [==============================] - 98s 228ms/step - loss: 0.0012 - PSNRLoss: 29.4095 - val_loss: 0.0030 - val_PSNRLoss: 25.6010\n",
      "\n",
      "Epoch 00153: val_PSNRLoss did not improve from 25.63435\n",
      "Epoch 154/200\n",
      "431/431 [==============================] - 97s 225ms/step - loss: 0.0012 - PSNRLoss: 29.2502 - val_loss: 0.0030 - val_PSNRLoss: 25.6316\n",
      "\n",
      "Epoch 00154: val_PSNRLoss did not improve from 25.63435\n",
      "Epoch 155/200\n",
      "431/431 [==============================] - 101s 234ms/step - loss: 0.0012 - PSNRLoss: 29.3708 - val_loss: 0.0030 - val_PSNRLoss: 25.6600\n",
      "\n",
      "Epoch 00155: val_PSNRLoss improved from 25.63435 to 25.65998, saving model to weight_9_5_7.h5\n",
      "Epoch 156/200\n",
      "431/431 [==============================] - 98s 226ms/step - loss: 0.0012 - PSNRLoss: 29.4204 - val_loss: 0.0030 - val_PSNRLoss: 25.6615\n",
      "\n",
      "Epoch 00156: val_PSNRLoss improved from 25.65998 to 25.66155, saving model to weight_9_5_7.h5\n",
      "Epoch 157/200\n",
      "431/431 [==============================] - 107s 248ms/step - loss: 0.0012 - PSNRLoss: 29.4705 - val_loss: 0.0030 - val_PSNRLoss: 25.5745\n",
      "\n",
      "Epoch 00157: val_PSNRLoss did not improve from 25.66155\n",
      "Epoch 158/200\n",
      "431/431 [==============================] - 103s 240ms/step - loss: 0.0012 - PSNRLoss: 29.3187 - val_loss: 0.0029 - val_PSNRLoss: 25.6923\n",
      "\n",
      "Epoch 00158: val_PSNRLoss improved from 25.66155 to 25.69229, saving model to weight_9_5_7.h5\n",
      "Epoch 159/200\n",
      "431/431 [==============================] - 95s 220ms/step - loss: 0.0012 - PSNRLoss: 29.4125 - val_loss: 0.0029 - val_PSNRLoss: 25.6846\n",
      "\n",
      "Epoch 00159: val_PSNRLoss did not improve from 25.69229\n",
      "Epoch 160/200\n",
      "431/431 [==============================] - 104s 240ms/step - loss: 0.0012 - PSNRLoss: 29.3596 - val_loss: 0.0029 - val_PSNRLoss: 25.6903\n",
      "\n",
      "Epoch 00160: val_PSNRLoss did not improve from 25.69229\n",
      "Epoch 161/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0012 - PSNRLoss: 30.0182 - val_loss: 0.0029 - val_PSNRLoss: 25.6914\n",
      "\n",
      "Epoch 00161: val_PSNRLoss did not improve from 25.69229\n",
      "Epoch 162/200\n",
      "431/431 [==============================] - 99s 229ms/step - loss: 0.0012 - PSNRLoss: 29.5184 - val_loss: 0.0029 - val_PSNRLoss: 25.7054\n",
      "\n",
      "Epoch 00162: val_PSNRLoss improved from 25.69229 to 25.70538, saving model to weight_9_5_7.h5\n",
      "Epoch 163/200\n",
      "431/431 [==============================] - 104s 240ms/step - loss: 0.0012 - PSNRLoss: 29.5239 - val_loss: 0.0029 - val_PSNRLoss: 25.7173\n",
      "\n",
      "Epoch 00163: val_PSNRLoss improved from 25.70538 to 25.71730, saving model to weight_9_5_7.h5\n",
      "Epoch 164/200\n",
      "431/431 [==============================] - 105s 245ms/step - loss: 0.0012 - PSNRLoss: 29.6301 - val_loss: 0.0031 - val_PSNRLoss: 25.5383\n",
      "\n",
      "Epoch 00164: val_PSNRLoss did not improve from 25.71730\n",
      "Epoch 165/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0012 - PSNRLoss: 29.4257 - val_loss: 0.0029 - val_PSNRLoss: 25.7051\n",
      "\n",
      "Epoch 00165: val_PSNRLoss did not improve from 25.71730\n",
      "Epoch 166/200\n",
      "431/431 [==============================] - 99s 229ms/step - loss: 0.0012 - PSNRLoss: 29.8299 - val_loss: 0.0029 - val_PSNRLoss: 25.7465\n",
      "\n",
      "Epoch 00166: val_PSNRLoss improved from 25.71730 to 25.74647, saving model to weight_9_5_7.h5\n",
      "Epoch 167/200\n",
      "431/431 [==============================] - 98s 227ms/step - loss: 0.0012 - PSNRLoss: 29.5373 - val_loss: 0.0029 - val_PSNRLoss: 25.7549\n",
      "\n",
      "Epoch 00167: val_PSNRLoss improved from 25.74647 to 25.75489, saving model to weight_9_5_7.h5\n",
      "Epoch 168/200\n",
      "431/431 [==============================] - 98s 227ms/step - loss: 0.0012 - PSNRLoss: 29.4663 - val_loss: 0.0029 - val_PSNRLoss: 25.7557\n",
      "\n",
      "Epoch 00168: val_PSNRLoss improved from 25.75489 to 25.75566, saving model to weight_9_5_7.h5\n",
      "Epoch 169/200\n",
      "431/431 [==============================] - 101s 234ms/step - loss: 0.0012 - PSNRLoss: 29.7775 - val_loss: 0.0029 - val_PSNRLoss: 25.7027\n",
      "\n",
      "Epoch 00169: val_PSNRLoss did not improve from 25.75566\n",
      "Epoch 170/200\n",
      "431/431 [==============================] - 103s 240ms/step - loss: 0.0012 - PSNRLoss: 29.5033 - val_loss: 0.0029 - val_PSNRLoss: 25.7655\n",
      "\n",
      "Epoch 00170: val_PSNRLoss improved from 25.75566 to 25.76549, saving model to weight_9_5_7.h5\n",
      "Epoch 171/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0012 - PSNRLoss: 29.5662 - val_loss: 0.0029 - val_PSNRLoss: 25.7716\n",
      "\n",
      "Epoch 00171: val_PSNRLoss improved from 25.76549 to 25.77156, saving model to weight_9_5_7.h5\n",
      "Epoch 172/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0012 - PSNRLoss: 29.6241 - val_loss: 0.0029 - val_PSNRLoss: 25.7810\n",
      "\n",
      "Epoch 00172: val_PSNRLoss improved from 25.77156 to 25.78102, saving model to weight_9_5_7.h5\n",
      "Epoch 173/200\n",
      "431/431 [==============================] - 104s 240ms/step - loss: 0.0012 - PSNRLoss: 29.6876 - val_loss: 0.0029 - val_PSNRLoss: 25.7748\n",
      "\n",
      "Epoch 00173: val_PSNRLoss did not improve from 25.78102\n",
      "Epoch 174/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0012 - PSNRLoss: 29.6881 - val_loss: 0.0029 - val_PSNRLoss: 25.7665\n",
      "\n",
      "Epoch 00174: val_PSNRLoss did not improve from 25.78102\n",
      "Epoch 175/200\n",
      "431/431 [==============================] - 98s 227ms/step - loss: 0.0012 - PSNRLoss: 29.7665 - val_loss: 0.0029 - val_PSNRLoss: 25.7945\n",
      "\n",
      "Epoch 00175: val_PSNRLoss improved from 25.78102 to 25.79448, saving model to weight_9_5_7.h5\n",
      "Epoch 176/200\n",
      "431/431 [==============================] - 99s 230ms/step - loss: 0.0012 - PSNRLoss: 29.5886 - val_loss: 0.0029 - val_PSNRLoss: 25.7170\n",
      "\n",
      "Epoch 00176: val_PSNRLoss did not improve from 25.79448\n",
      "Epoch 177/200\n",
      "431/431 [==============================] - 106s 247ms/step - loss: 0.0012 - PSNRLoss: 29.9556 - val_loss: 0.0029 - val_PSNRLoss: 25.8124\n",
      "\n",
      "Epoch 00177: val_PSNRLoss improved from 25.79448 to 25.81244, saving model to weight_9_5_7.h5\n",
      "Epoch 178/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0012 - PSNRLoss: 29.6505 - val_loss: 0.0029 - val_PSNRLoss: 25.8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00178: val_PSNRLoss improved from 25.81244 to 25.82043, saving model to weight_9_5_7.h5\n",
      "Epoch 179/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0012 - PSNRLoss: 29.7911 - val_loss: 0.0029 - val_PSNRLoss: 25.7180\n",
      "\n",
      "Epoch 00179: val_PSNRLoss did not improve from 25.82043\n",
      "Epoch 180/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0012 - PSNRLoss: 29.5134 - val_loss: 0.0029 - val_PSNRLoss: 25.7439\n",
      "\n",
      "Epoch 00180: val_PSNRLoss did not improve from 25.82043\n",
      "Epoch 181/200\n",
      "431/431 [==============================] - 96s 224ms/step - loss: 0.0012 - PSNRLoss: 29.5909 - val_loss: 0.0029 - val_PSNRLoss: 25.7790\n",
      "\n",
      "Epoch 00181: val_PSNRLoss did not improve from 25.82043\n",
      "Epoch 182/200\n",
      "431/431 [==============================] - 99s 229ms/step - loss: 0.0012 - PSNRLoss: 29.5391 - val_loss: 0.0029 - val_PSNRLoss: 25.8021\n",
      "\n",
      "Epoch 00182: val_PSNRLoss did not improve from 25.82043\n",
      "Epoch 183/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0012 - PSNRLoss: 29.5073 - val_loss: 0.0029 - val_PSNRLoss: 25.7988\n",
      "\n",
      "Epoch 00183: val_PSNRLoss did not improve from 25.82043\n",
      "Epoch 184/200\n",
      "431/431 [==============================] - 99s 230ms/step - loss: 0.0012 - PSNRLoss: 29.7877 - val_loss: 0.0030 - val_PSNRLoss: 25.6712\n",
      "\n",
      "Epoch 00184: val_PSNRLoss did not improve from 25.82043\n",
      "Epoch 185/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0012 - PSNRLoss: 29.7716 - val_loss: 0.0029 - val_PSNRLoss: 25.8358\n",
      "\n",
      "Epoch 00185: val_PSNRLoss improved from 25.82043 to 25.83579, saving model to weight_9_5_7.h5\n",
      "Epoch 186/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0012 - PSNRLoss: 29.9464 - val_loss: 0.0028 - val_PSNRLoss: 25.8770\n",
      "\n",
      "Epoch 00186: val_PSNRLoss improved from 25.83579 to 25.87698, saving model to weight_9_5_7.h5\n",
      "Epoch 187/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0012 - PSNRLoss: 29.9146 - val_loss: 0.0028 - val_PSNRLoss: 25.8984\n",
      "\n",
      "Epoch 00187: val_PSNRLoss improved from 25.87698 to 25.89839, saving model to weight_9_5_7.h5\n",
      "Epoch 188/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0012 - PSNRLoss: 29.7342 - val_loss: 0.0029 - val_PSNRLoss: 25.7063\n",
      "\n",
      "Epoch 00188: val_PSNRLoss did not improve from 25.89839\n",
      "Epoch 189/200\n",
      "431/431 [==============================] - 104s 241ms/step - loss: 0.0012 - PSNRLoss: 29.8529 - val_loss: 0.0028 - val_PSNRLoss: 25.9016\n",
      "\n",
      "Epoch 00189: val_PSNRLoss improved from 25.89839 to 25.90160, saving model to weight_9_5_7.h5\n",
      "Epoch 190/200\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 0.0011 - PSNRLoss: 29.7755 - val_loss: 0.0028 - val_PSNRLoss: 25.8796\n",
      "\n",
      "Epoch 00190: val_PSNRLoss did not improve from 25.90160\n",
      "Epoch 191/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0011 - PSNRLoss: 29.5629 - val_loss: 0.0028 - val_PSNRLoss: 25.8746\n",
      "\n",
      "Epoch 00191: val_PSNRLoss did not improve from 25.90160\n",
      "Epoch 192/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0011 - PSNRLoss: 29.9116 - val_loss: 0.0028 - val_PSNRLoss: 25.9165\n",
      "\n",
      "Epoch 00192: val_PSNRLoss improved from 25.90160 to 25.91647, saving model to weight_9_5_7.h5\n",
      "Epoch 193/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0011 - PSNRLoss: 29.8303 - val_loss: 0.0028 - val_PSNRLoss: 25.8604\n",
      "\n",
      "Epoch 00193: val_PSNRLoss did not improve from 25.91647\n",
      "Epoch 194/200\n",
      "431/431 [==============================] - 100s 233ms/step - loss: 0.0011 - PSNRLoss: 29.7346 - val_loss: 0.0028 - val_PSNRLoss: 25.9091\n",
      "\n",
      "Epoch 00194: val_PSNRLoss did not improve from 25.91647\n",
      "Epoch 195/200\n",
      "431/431 [==============================] - 102s 237ms/step - loss: 0.0011 - PSNRLoss: 29.7565 - val_loss: 0.0028 - val_PSNRLoss: 25.9218\n",
      "\n",
      "Epoch 00195: val_PSNRLoss improved from 25.91647 to 25.92182, saving model to weight_9_5_7.h5\n",
      "Epoch 196/200\n",
      "431/431 [==============================] - 99s 230ms/step - loss: 0.0011 - PSNRLoss: 29.6548 - val_loss: 0.0029 - val_PSNRLoss: 25.8386\n",
      "\n",
      "Epoch 00196: val_PSNRLoss did not improve from 25.92182\n",
      "Epoch 197/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0011 - PSNRLoss: 29.8503 - val_loss: 0.0028 - val_PSNRLoss: 25.8903\n",
      "\n",
      "Epoch 00197: val_PSNRLoss did not improve from 25.92182\n",
      "Epoch 198/200\n",
      "431/431 [==============================] - 100s 232ms/step - loss: 0.0011 - PSNRLoss: 29.9019 - val_loss: 0.0028 - val_PSNRLoss: 25.9361\n",
      "\n",
      "Epoch 00198: val_PSNRLoss improved from 25.92182 to 25.93609, saving model to weight_9_5_7.h5\n",
      "Epoch 199/200\n",
      "431/431 [==============================] - 104s 242ms/step - loss: 0.0011 - PSNRLoss: 29.8284 - val_loss: 0.0028 - val_PSNRLoss: 25.9255\n",
      "\n",
      "Epoch 00199: val_PSNRLoss did not improve from 25.93609\n",
      "Epoch 200/200\n",
      "431/431 [==============================] - 98s 227ms/step - loss: 0.0011 - PSNRLoss: 30.0214 - val_loss: 0.0029 - val_PSNRLoss: 25.8311\n",
      "\n",
      "Epoch 00200: val_PSNRLoss did not improve from 25.93609\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "# sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=adam, loss='mse', metrics=[PSNRLoss])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callback_list = [callbacks.ModelCheckpoint('1608Stable_adam_checkpoint.h5', monitor='val_PSNRLoss', save_best_only=True,\n",
    "                                           mode='max', save_weights_only=True, verbose=1)]\n",
    "\n",
    "batch_size = 20\n",
    "nb_epoch = 200\n",
    "\n",
    "history = model.fit([trainX_1,trainX_2,trainX_3], trainY, batch_size=batch_size, epochs=nb_epoch, callbacks=callback_list,\n",
    "                    verbose=1, validation_data=([testX_1, testX_2, testX_3], testY))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYXHWd7/H3t5buTi/pTicdIAmQsClhCxACKq6MGlxABQEdFB1G9N7huTpc0fCojPrMfa7MODrXK+rgwAyrgCBjRuECyiKjbE0IkLBlIZgFsnenO73V8r1//E53V3equjvLqep0Pq/nqadP/c6pU9+qdOrTv9/v1Dnm7oiIiIwkUekCRERk/FNYiIjIqBQWIiIyKoWFiIiMSmEhIiKjUliIiMioFBYiIjIqhYXIHjCzNWbWZ2bThrU/a2ZuZrPNbJaZ3W1mW8ys3cyWmdnnou1mR9t1DrtdWJEXJDKKVKULENmPvQZ8Cvi/AGZ2AlBbsP5m4DngcKAXOAE4eNg+mtw9G3+pIntHPQuRPXcz8NmC+5cANxXcPw34d3ff6e5Zd3/W3e8ra4Ui+4jCQmTPPQFMNrNjzSwJXATcMmz9tWZ2kZkdVpEKRfYRhYXI3unvXbwfeAlYX7Duk8BjwLeA18xsqZmdNuzxW8ysreB2bFmqFtlNmrMQ2Ts3A38A5jB0CAp33w4sAhZFE+HfB/7DzGYVbDZNcxayP1DPQmQvuPvrhInuDwG/GmG7LYSwmAE0l6c6kX1HYSGy9y4F3ufuOwsbzewaMzvezFJm1gD8N2Clu2+tSJUie0FhIbKX3H2Vu7cWWVUL3AO0AasJh9CeM2ybtmHfs7gi5nJF9ojp4kciIjIa9SxERGRUCgsRERmVwkJEREalsBARkVFNmC/lTZs2zWfPnl3pMkRE9ivPPPPMFndvGW27CRMWs2fPprW12NGLIiJSipm9PpbtNAwlIiKjUliIiMioFBYiIjKqCTNnUUwmk2HdunX09PRUupTY1dTUMGvWLNLpdKVLEZEJaEKHxbp162hoaGD27NmYWaXLiY27s3XrVtatW8ecOXMqXY6ITEATehiqp6eHqVOnTuigADAzpk6dekD0oESkMiZ0WAATPij6HSivU0QqY8KHxWj6snnebO+hN5OrdCkiIuPWAR8W2XyeTR099Gbzsey/ra2Nn/zkJ7v9uA996EO0tbXFUJGIyO474MOif/Amrqt6lAqLbHbkyy7fe++9NDU1xVSViMjumdBHQ41NvHGxaNEiVq1axbx580in09TU1DBlyhRefvllXn31VT72sY+xdu1aenp6+PKXv8xll10GDJ6+pLOzk7PPPpszzzyTP/3pT8ycOZNf//rXTJo0KZZ6RUSKOWDC4jv/uZwXN+zYpT3vTndfjup0klRi9yaJ586YzN999LgRt/ne977HsmXLWLp0KY888ggf/vCHWbZs2cAhrjfccAPNzc10d3dz2mmncd555zF16tQh+1ixYgW/+MUv+PnPf84FF1zA3XffzcUXX7xbtYqI7I0DJizGiwULFgz5LsSPfvQj7rnnHgDWrl3LihUrdgmLOXPmMG/ePABOPfVU1qxZU7Z6RUTgAAqLUj2A3kyOVzZ2cGhzLVNqq2Kvo66ubmD5kUce4Xe/+x2PP/44tbW1vOc97yn6XYnq6uqB5WQySXd3d+x1iogUOuAnuOOe4W5oaKCjo6Pouvb2dqZMmUJtbS0vv/wyTzzxRDxFiIjspVjDwswWmtkrZrbSzBYVWV9tZndE6580s9lR+2wz6zazpdHtZ7HVGP2M62ioqVOn8o53vIPjjz+eK6+8csi6hQsXks1mOfbYY1m0aBFnnHFGTFWIiOyd2IahzCwJXAu8H1gHPG1mi939xYLNLgW2u/tRZnYRcA1wYbRulbvPi6u+gkqjn3HFBdx2221F26urq7nvvvuKruufl5g2bRrLli0baP/qV7+6z+sTERlNnD2LBcBKd1/t7n3A7cC5w7Y5F7gxWr4LOMvKfN6K/mfz+LJCRGS/F2dYzATWFtxfF7UV3cbds0A70H8o0Bwze9bMHjWzdxZ7AjO7zMxazax18+bN+7Z6EREZMF4nuN8ADnP3k4ErgNvMbPLwjdz9Onef7+7zW1pGvd54UfEPQomI7P/iDIv1wKEF92dFbUW3MbMU0Ahsdfded98K4O7PAKuAY2KsVcNQIiIjiDMsngaONrM5ZlYFXAQsHrbNYuCSaPl84CF3dzNriSbIMbMjgKOB1XEUqTN7i4iMLrajodw9a2aXA/cDSeAGd19uZt8FWt19MXA9cLOZrQS2EQIF4F3Ad80sA+SBL7n7tngqDWnhGogSESkp1jkLd7/X3Y9x9yPd/X9FbVdHQYG797j7J939KHdf4O6ro/a73f04d5/n7qe4+3/GVeNAxyKmrNjTU5QD/PM//zNdXV37uCIRkd03Xie4y6f/0NmYdq+wEJGJ4IA5N1QpcU9ZFJ6i/P3vfz/Tp0/nzjvvpLe3l49//ON85zvfYefOnVxwwQWsW7eOXC7Ht771LTZu3MiGDRt473vfy7Rp03j44YdjrlREpLQDJyzuWwRvvrBLswFH9GapSiUguZsdrYNPgLO/N+Imhacof+CBB7jrrrt46qmncHfOOecc/vCHP7B582ZmzJjBb3/7WyCcM6qxsZEf/OAHPPzww0ybNm336hIR2cc0DDUg/gnuBx54gAceeICTTz6ZU045hZdffpkVK1Zwwgkn8OCDD/L1r3+dxx57jMbGxthrERHZHQdOz2KEHsBr69uZVl/FIY3xXn3O3bnqqqv44he/uMu6JUuWcO+99/LNb36Ts846i6uvvjrWWkREdod6FsQ7b1F4ivIPfvCD3HDDDXR2dgKwfv16Nm3axIYNG6itreXiiy/myiuvZMmSJbs8VkSkkg6cnsUo4voGd+Epys8++2w+/elP87a3vQ2A+vp6brnlFlauXMmVV15JIpEgnU7z05/+FIDLLruMhQsXMmPGDE1wi0hFmU+Q81zMnz/fW1tbh7S99NJLHHvssaM+dvmGdqbUVjGjKd5hqLiN9fWKiPQzs2fcff5o22kYKjIxIlNEJB4KC8AwnUlQRGQEEz4sxjTMZvt/z2KiDCeKyPg0ocOipqaGrVu3jvpBarBfp4W7s3XrVmpqaipdiohMUBP6aKhZs2axbt06RruK3pvtPWxPJejYWFWmyva9mpoaZs2aVekyRGSCmtBhkU6nmTNnzqjbXfYPD3Ha4c384EIdSSQiUsyEHoYaq6QZOY35i4iUpLAAEmbk8goLEZFSFBZAImHk1bMQESlJYUE0DKWehYhISQoLQs8il690FSIi45fCgnDNIw1DiYiUprBAw1AiIqNRWKAJbhGR0SgsUM9CRGQ0Cgv6J7gVFiIipSgsCD0LDUOJiJSmsACS6lmIiIxIYUE0DKWsEBEpSWEBJA3y6lmIiJSksEDDUCIio4k1LMxsoZm9YmYrzWxRkfXVZnZHtP5JM5s9bP1hZtZpZl+Ns86EJrhFREYUW1iYWRK4FjgbmAt8yszmDtvsUmC7ux8F/BC4Ztj6HwD3xVVjP/UsRERGFmfPYgGw0t1Xu3sfcDtw7rBtzgVujJbvAs4yMwMws48BrwHLY6wR6J/gVliIiJQSZ1jMBNYW3F8XtRXdxt2zQDsw1czqga8D3xnpCczsMjNrNbPW0a6zPZKkmSa4RURGMF4nuL8N/NDdO0fayN2vc/f57j6/paVlj58sqZ6FiMiIUjHuez1waMH9WVFbsW3WmVkKaAS2AqcD55vZPwBNQN7Metz9x3EUmjAjr+tZiIiUFGdYPA0cbWZzCKFwEfDpYdssBi4BHgfOBx5ydwfe2b+BmX0b6IwrKCBcz0IT3CIipcUWFu6eNbPLgfuBJHCDuy83s+8Cre6+GLgeuNnMVgLbCIFSdhqGEhEZWZw9C9z9XuDeYW1XFyz3AJ8cZR/fjqW4AglNcIuIjGi8TnCXlXoWIiIjU1gQehaasxARKU1hQehZaBhKRKQ0hQUahhIRGY3CAn3PQkRkNAoLou9ZqGchIlKSwoJwbihNcIuIlKawIJx1FnS1PBGRUhQWhJ4FaChKRKQUhQWDPQsNRYmIFKewIBw6C+jSqiIiJSgsKBiGUs9CRKQohQWFE9wVLkREZJxSWADJkBWa4BYRKUFhweCchYahRESKU1hQMAylnoWISFEKCwYnuBUWIiLFKSzQ9yxEREajsKCgZ6GjoUREilJY5PPUZHdQRUZHQ4mIlKCwWP8MH77vbbw9sVzDUCIiJSgsqusBqKVHE9wiIiUoLKrqAKizHvUsRERKUFhUhZ5FPd0KCxGREhQW1Q0A1GkYSkSkJIVFMk0uUUW9hqFEREpSWAC5dB11dKtnISJSgsICyKfrqbUecvpSnohIUQoLIJeqpR4NQ4mIlKKwIPQsNAwlIlJarGFhZgvN7BUzW2lmi4qsrzazO6L1T5rZ7Kh9gZktjW7PmdnH46wzX1WnCW4RkRHEFhZmlgSuBc4G5gKfMrO5wza7FNju7kcBPwSuidqXAfPdfR6wEPgXM0vFVWvoWfTo3FAiIiXE2bNYAKx099Xu3gfcDpw7bJtzgRuj5buAs8zM3L3L3bNRew0Q66e4V9VRZ93k1bMQESkqzrCYCawtuL8uaiu6TRQO7cBUADM73cyWAy8AXyoIjwFmdpmZtZpZ6+bNm/e4UE/XhZ6FwkJEpKhxO8Ht7k+6+3HAacBVZlZTZJvr3H2+u89vaWnZ8+eqCsNQeV3QQkSkqDjDYj1waMH9WVFb0W2iOYlGYGvhBu7+EtAJHB9XoV5VT8ryeLY3rqcQEdmvxRkWTwNHm9kcM6sCLgIWD9tmMXBJtHw+8JC7e/SYFICZHQ68FVgTW6VV4fxQlumM7SlERPZnsR1h5O5ZM7scuB9IAje4+3Iz+y7Q6u6LgeuBm81sJbCNECgAZwKLzCwD5IH/7u5b4qq1/5oWiT6FhYhIMbGFBYC73wvcO6zt6oLlHuCTRR53M3BznLUNUaWwEBEZyZiGoczsy2Y22YLrzWyJmX0g7uLKJroAUiLbVeFCRETGp7HOWfyVu+8APgBMAT4DfC+2qsrMasKcRVI9CxGRosYaFhb9/BBws7svL2jb71n/MFR2Z4UrEREZn8YaFs+Y2QOEsLjfzBoIE88TQ3S1vJSOhhIRKWqsE9yXAvOA1e7eZWbNwOfjK6u8Ev3DUBn1LEREihlrz+JtwCvu3mZmFwPfJJyaY0JIRMNQyWx3hSsRERmfxhoWPwW6zOwk4H8Cq4CbYquqzBLpNL2eJqU5CxGRosYaFll3d8JZYn/s7tcCDfGVVV7JhNFJjcJCRKSEsc5ZdJjZVYRDZt9pZgkgHV9Z5ZUwY6crLEREShlrz+JCoJfwfYs3CScF/MfYqiqzZMLYySTSOYWFiEgxYwqLKCBuBRrN7CNAj7tPmDmLpGkYSkRkJGM93ccFwFOE8zhdADxpZufHWVg5JRJGl9eQzuloKBGRYsY6Z/EN4DR33wRgZi3A7wiXQp0QOqmlOruh0mWIiIxLY52zSPQHRWTrbjx2v9BOPdXZjkqXISIyLo21Z/H/zOx+4BfR/QsZdurx/d0Oq2dSdge4g02Y016JiOwTYwoLd7/SzM4D3hE1Xefu98RXVvntoJ4EOejtgJrJlS5HRGRcGfPFj9z9buDuGGupqI5E9B3D7u0KCxGRYUYMCzPrALzYKsDdfcJ8qnZYQ3il3dthyuGVLkdEZFwZMSzcfcKc0mM0HVY/GBYiIjLEhDqiaW90Fg5DiYjIEAqLSKcpLERESlFYRLrUsxARKUlhEckmq+i1GoWFiEgRCotI0oyuZAN0t1W6FBGRcUdhEUkkjJ2JBvUsRESKUFhEQs9issJCRKQIhUUkmbBw+KzCQkRkFwqLSMIsHD6rsBAR2YXCIjKkZ+HFznAiInLgijUszGyhmb1iZivNbFGR9dVmdke0/kkzmx21v9/MnjGzF6Kf74uzTggT3B2Jesj1QkZXzBMRKRRbWJhZErgWOBuYC3zKzOYO2+xSYLu7HwX8ELgmat8CfNTdTwAuAW6Oq85+SdO3uEVESomzZ7EAWOnuq929D7gdOHfYNucCN0bLdwFnmZm5+7Pu3n+N0+XAJDOrjrFWkgljh9WHOwoLEZEh4gyLmcDagvvrorai27h7FmgHpg7b5jxgibv3Dn8CM7vMzFrNrHXz5s17VWzCjA7UsxARKWZcT3Cb2XGEoakvFlvv7te5+3x3n9/S0rJXzzW0Z7Ftr/YlIjLRxBkW64FDC+7PitqKbmNmKaAR2BrdnwXcA3zW3VfFWCcQwmKLNYc7O96I++lERPYrcYbF08DRZjbHzKqAi4DFw7ZZTJjABjgfeMjd3cyagN8Ci9z9jzHWOCBhxnYmQ7oOtq8px1OKiOw3YguLaA7icuB+4CXgTndfbmbfNbNzos2uB6aa2UrgCqD/8NrLgaOAq81saXSbHletEHoWeSdcUrXt9TifSkRkvzPiZVX3lrvfC9w7rO3qguUe4JNFHvf3wN/HWdtwCTNyeYdps9WzEBEZZlxPcJdTVcroy+Wh6XDY/rq+xS0iUkBhEWmuq2JrZy9MmQ2ZndC1tdIliYiMGwqLyPSGGrZ3ZchMjg7g0lCUiMgAhUWkpSF8Qbyt+pDQoLAQERmgsIi01IeweNMODg0KCxGRAQqLyPTJISw29iShrkWHz4qIFFBYRPqHoTb3T3KrZyEiMkBhEZlaF8Ji044oLLau0uGzIiIRhUWkKpWgua6KzZ09cOjpsGM9bFtd6bJERMYFhUWBlvrq0LM4Mrow36qHKluQiMg4obAo0NJQHeYsmo8I3+Re9XClSxIRGRcUFgWmN1SzuaMXzELv4rU/QC5T6bJERCpOYVGgpaGaTR29uHsIi74OWNda6bJERCpOYVGgpaGavmyeHT1ZmPMuSKThpf+sdFkiIhWnsCgw8F2Ljl6Y1ATHfBCW3QW5bIUrExGpLIVFgf6w2NTRExpOvBA6N8Jrj1SuKBGRcUBhUWB6Qw0AG3dEYXHMB6GmEZ6/s4JViYhUnsKiwKHNk0gmjNWbd4aGVDUc9/Ewb9HbWdniREQqSGFRoDqV5PCptazYWBAMJ14EmS54+TeVK0xEpMIUFsMcPb2eFZs6BhsOPR2aDoPn76hcUSIiFaawGObo6Q2s2dpFXzYfGhKJMNG9+hHoeLOitYmIVIrCYpijD6onl3fWbN052HjiheB5eOGuyhUmIlJBCothjppeDzB03mLa0TDjFHj+9gpVJSJSWQqLYY5sqceMofMWACddBG++ABtfrExhIiIVpLAYpiad5LDmWlZsGnao7HGfAEtqoltEDkgKiyKOnl7Pq28O61nUt8BRfxG+oKfTf4jIAUZhUcTxMxtZubmT9u5hpyef/3no2AAv/LIyhYmIVIjCoogFc5pxhyWvbx+64piFcNAJ8Nj3IZ+rTHEiIhWgsCji5EOnkE4aT762begKM3j3lbB1JSz7VWWKExGpAIVFEZOqkpw4q4mnXtu668q3fhQOOh4e/nvI9pa/OBGRCog1LMxsoZm9YmYrzWxRkfXVZnZHtP5JM5sdtU81s4fNrNPMfhxnjaUsmNPMC+vb6e4bNtyUSMD7vwPb10DrDZUoTUSk7GILCzNLAtcCZwNzgU+Z2dxhm10KbHf3o4AfAtdE7T3At4CvxlXfaBbMbiaTc55du33XlUf9BRzxXnj0Gti5pfzFiYiUWZw9iwXASndf7e59wO3AucO2ORe4MVq+CzjLzMzdd7r7fxFCoyLmz55CVTLB717cVHyDhf87nLb8vq+VtzARkQqIMyxmAmsL7q+L2opu4+5ZoB2YOtYnMLPLzKzVzFo3b968l+UO1VCT5qxjp7P4ufVkcvldN5h+LLz767DsbnhJpy8XkYltv57gdvfr3H2+u89vaWnZ5/v/xCmz2NLZx2MrSgTRmV+BlmPh99+BfJFAERGZIOIMi/XAoQX3Z0VtRbcxsxTQCBQ5BKky3n1MC811Vdy9ZHjZkWQa3v012PIqvLS4vMWJiJRRnGHxNHC0mc0xsyrgImD4J+pi4JJo+XzgIXf3GGvaLVWpBOecNIMHl29kU0eJ6ZO558LUo+EP34fxU7qIyD4VW1hEcxCXA/cDLwF3uvtyM/uumZ0TbXY9MNXMVgJXAAOH15rZGuAHwOfMbF2RI6nK4rNvO5xMPs8tj79efINEEt51JWx8AZ7+1/IWJyJSJjaO/pDfK/Pnz/fW1tZY9v3XN7byzOvb+NOis5hUldx1A3e49XxY80f40mPh+hciIvsBM3vG3eePtt1+PcFdLl945xy2d2W4s3Vt8Q3M4JwfQ7oG7vo8ZLrLW6CISMwUFmOwYE4zp89p5ke/X8GOnkzxjSYfAh/7abhA0n1f0/yFiEwoCosxMDO+9ZG5bOvq49qHVpbe8C1nw5l/C0tugl9dBr0dpbcVEdmPKCzG6PiZjZx3yixu+ONrrNg4Qgi871vw3m/Csrvg+g9Ax8byFSkiEhOFxW646uy3Ul+d4sq7nieXLzHMlEiG05hf/CvY/jr820J447nyFioiso8pLHbD1Ppqvn3OcSxd28bPHl018sZHvhc++x/h/FHXvRd+cwVsGWEIS0RkHFNY7KZzTprBR0+awfcfeIX7l7858saHLoDLn4JTLwnzGD8+FX75Odj0cllqFRHZVxQWu8nM+MfzT+TEmY387R1LWb6hfeQHTJoCH/kh/O1yeOf/hBUPwk/OgLsuhdce0+VZRWS/oC/l7aFNO3o499o/YsB/XP4OpjfUjO2BO7fCn34ET10HmS6oPxjmfRpO+Qw0HxFrzSIiw431S3kKi72wbH07n/zZ4xzWXMutXzidafXVY39wbyeseACevyP89DzMeTec8ll460fCF/xERGKmsCiTP63cwqU3tjJzyiRu++vTmT55Dz7k29fD0tvg2Zug7c9Q0xgC46Dj4OgP6PQhIhIbhUUZPbl6K5//96c5aHINt33hdA5pnLRnO8rn4bVHYemtsPL30L0ttM9+J8w+M/w89HRIpvZd8SJyQFNYlNkzr2/jkhuepr46xXWfPZUTZzXt/U53bIBnb4Flv4LNLwMO6bowtzHlcGieEy6+dNBx0PIWSO9hSInIAUthUQEvbtjBF25qZUtnL9/88LFcfMbhmNm+2XlPO6x+BF7/E2xfE27bXoNcb1ifSMGsBTDzFGg4GBoOCT8bZ0HDDEhV7Zs6RGRCUVhUyJbOXq648zn+8Opm3n7kVL7x4WM5bkZjPE+Wz8G21bBxOWx4FlY/DJtfgezwCzUZ1EyGRDrMf0yZDX2dMO0YmHlqOLw3kRo8+WHjLJg8I5xNV0QmNIVFBbk7tzz5Z/7pgVdo787wiZNnccUHjmFmUxmGidxDL6RzYxjG2rEe2tdB17YQIpteCu3pmtAz8RLf86hphGQVTJkDh78dquuhriVcFbC6AVI1kKoO2yTT0S3qveQykK7V3IrIfkBhMQ60d2f4ycMr+bc/riHnzgePO4jPvm02p89p3nfDU3ujtxO2vAI9OwZDw4Ftq8J1xfNZeHMZbFgSDu3dXdWTYVITTD8OZsyDqroQJPkc1DZD/fQQStnesK5xVhg+S6TCcyfT+/TlisiuFBbjyPq2bm56fA13PL2Wtq4MR7bUcc5JMzln3gzmTKurdHmjy+fDh3fHGyFI+rpCLyXbEz78cxnIZyDXF3o2yTT07YTuNti5OQyRbRvlXFr9LBFu+WwIjprGsK9UTQiUqvpwssaayWEYzT08b6oaUpPC9s1HhMn+vp2hh5WqgfqWEELd22HnltBLSqQg2w0HnQBTjwzPuWVF+LJk4yyomw6JfXCSg87NsOxuOOnCMOQnMo4oLMahnkyOxc9t4O5n1vHUmm24w9xDJvPet7bw7mOmc/JhTaSTE/QMLLlMuIJgMg2WhK6tIUh62sOHee+OMFy2Y33YNlkFba+HuZWq+hBMfTvDLZ+Dri1hGM0MktVhfakhtT2VrApzN3XTw2HM2d4QKuk6wKM5nmE/k2loOiy8xr6OUPtzt4fHNx0G714Ugq1uWliX6Qrhm+kK+6+fDpNnDh3aS6SH3S+4tG8+HwLxjaWhJ3fYGUPXi4xCYTHOvdHezW+ee4MHX9zIM3/eTi7v1FYlOWlWEycf1sTJh03h5MOadu9b4QeafC7qiURDerlMmJvZtir0NtK14cM32xuCKZ+FmqbwQd25KQytJdOh57PjjbCf5iPCnEz7OmhfG74wuXMTTGoOH/JbV4b9YWBEP23wZ7YvhJx76An1tMEh8+D0L8KDfwc71u2DF26Dc0WZ7qEhWdMYXnc+N3TosL/GqroQWqnqsE0+A21rQwjPmh/en2x3eI21U6Hp8LCffCa8pvrpIZi3rgoHV1RPhmM+EAI1mQ69tf7aEqloXqs63O9pg7VPwfJ7wvt86udCDy9dG+bQLDnYsxwyTGuDr6EwCLu3Qy4beo0jcQ/DqtWTwxUtZQiFxX5kR0+GP67YwuOrt7J0bRsvbthBNrpexvSGao6aXs/R0+s5ano9R7bUM6NpEgc31lCT1l+Q45774AdfpjuEkOdDWGW6oao2DJml68IHasebYbgvn42G+Pqi5b5ouK9gOZcJj60/CA4+ATrfhNWPhm0S0QcvxmDvh9CTa18bHptIhg/0yTPCEN76Vsj0REN61aHHsnNz9EKiMOwPoNqp4QN/xxu7H4DT3hICdZej9sagenLoiWZ7oTc6iWfDjBCSUBDcicHeWOcm2P7a4HNPPiS83v5Q6t0BXdsH59Dy2Shsc9FydD8f3U9Vhx5m9eQQsv3ze6macEvXhP2nqsK/9/bX4ZCToOWtYfi0uiE85s9PhKMRZ80f7HlbIszz9XaEfVfVhVs+F/4ISqTDv3d9S1ju7Qih3XQoHPfx3X8/UVjs13oyOV5Y387SP7fxysYOVmzqZNWmTjp7s0O2m1pXxYymSRzSWDPwc/rkapomVdFUm6aptoqmSWkmT0qTTIyDCXXZ/2R7Q6AkkmHIq2tL+ADun3txD72tvs7wV37/3FWuP9QKbv3zSdPnhh7ga4+G4bdMd9RDyocnVGmUAAAL6UlEQVQP6MIeUeHHk+fCPFi2O/ReGg8NH65vPh8eXxiKnh8M2/SkcNqc3g5Y+2QIwGxP2LfnwnDgpCkhHPs6w4dwIhXmqxKpcLPkYLj2dYaeVaY7BMK0YwYDLNsdAjfbE9bXHxS+QLt+SQjzfpaEg4+HjS+G92xvHX8enH/DHj1UYTHBuDsbd/SyenMnG9p7eKOtO/xs72ZDWzdvtPXQMSxM+pnB5Jo0U2rTNEYBMiUKk8aC5cKAmVJbRUNNioRCRmTfyPaGIxB728Ow5qSmEH471g/2SvLZMLxWMzmEWN/OEE5EQ6SeH+zx5bNhCK95zl4dODHWsNCB8PsJM+PgxhoObix9osIdPRm2dvbR1tVHW1eGtu7wc3tXhvauPrZ3ZWjrztDW1cdrW3bS1tXHjp7iAROeExonpWmalKa2KkVddZJJVSnqqpLUVqWorUpSW52krn954GeSuuoUk6oK14W26lRifBw2LFJu/cN7dVMH2yY1hVuhKYePvJ/q+jAMVmYKiwlkck2ayTVpYOyH4+byTnsUINu7MrQPC5gQLhm6+rJ09eVo787wZns3O3tzA2292bF/ByNhDAmV/uVJVUmqUwmqU9HPdLScLmhLJahOFyxH62sGthvctiqVIJ1MkE5a9DOhoTiRvaCwOMAlE0ZzXRXNdXt+7qhsLk93JkdXX46dvSFAwi070NadybGzN0d3X5adQ9aF5Z29WbbtzNObzdObzdGbCcs9md0Lo5EkDNLJBFXJBKmCECkMlHQqQTphA8tVSSOViNqTNuSxVdFjCu8PX04mwuOTCUgmEqQSRiJhpBJh3cDNom2T/evCtgP7TxTuL/xUD03KSWEhey2VTNCQTNBQE883rt2dvlwUJJkoTAqCpLCtvz2Ty5PJ5snmw2MzWQ9t+cHlbD5PX397Lk8mV7icp7s7V2Kdk8lG+8o5uXxl5v0SFsI+YTYQQoXB07+uP2ASw9cljKRBKpEgkRi6r4Hl5OA+dn3s0MAbUocZyQS7PqcZ7j4wb50wI2FhmLV/OWEWjpI1C3PMZtH6odsno/UlHztk34Ovr9T6/jazwbqLrk8w6vO5e/jdi34H+/8gSe3HIa+wkHHPzKLhpSSMwwsI5vM+EByZbBQoeR8Iq7w72ShUcu7k8nlyecjm86EtumXzHu0rbJPJhcdlB0JpMJwGbh4eM/B4D8sDzxmtL1yXyxNqcAYem8uHMCzc9+D2/XUX21dhHeE1VSg7x43+LCh27JBFvdtUwjDC77ZFX9mxgrDZdV0UTIXtBkZ4zPveehBXf3RurK9LYSGylxIJozqRpDoF6DuUuDt5Z2jguJPLhfv9H4YQjl7Ne2jP58EJj83nHfeCdb7rfkut728bXB/2ly9YP3Tb/seGGgr3OWR9vvDx7LK/XH5w2YGqZJg7SyaMXNTLyOTy9OWcbC4fjtz18Jo9eo7+9yO0R20+uF3eiz/msOb4T1Iaa1iY2ULg/wBJ4F/d/XvD1lcDNwGnAluBC919TbTuKuBSIAf8D3e/P85aRWTfCENE6ICCCSa2ExGZWRK4FjgbmAt8ysyG95MuBba7+1HAD4FrosfOBS4CjgMWAj+J9iciIhUQ51nrFgAr3X21u/cBtwPnDtvmXODGaPku4CwLsz/nAre7e6+7vwasjPYnIiIVEGdYzATWFtxfF7UV3cbds0A7MHWMj8XMLjOzVjNr3bx58/DVIiKyj+zX58N29+vcfb67z29pGeXMkyIissfiDIv1wKEF92dFbUW3MbMU0EiY6B7LY0VEpEziDIungaPNbI6ZVREmrBcP22YxcEm0fD7wkIczGy4GLjKzajObAxwNPBVjrSIiMoLYDp1196yZXQ7cTzh09gZ3X25m3wVa3X0xcD1ws5mtBLYRAoVouzuBF4Es8Dfu+/oyaCIiMlY6RbmIyAHsgLuehZltBl7fi11MA7bso3L2JdW1e1TX7huvtamu3bOndR3u7qMeITRhwmJvmVnrWNK13FTX7lFdu2+81qa6dk/cde3Xh86KiEh5KCxERGRUCotB11W6gBJU1+5RXbtvvNamunZPrHVpzkJEREalnoWIiIxKYSEiIqM64MPCzBaa2StmttLMFlWwjkPN7GEze9HMlpvZl6P2b5vZejNbGt0+VKH61pjZC1ENrVFbs5k9aGYrop9TylzTWwrel6VmtsPMvlKJ98zMbjCzTWa2rKCt6PtjwY+i37nnzeyUMtf1j2b2cvTc95hZU9Q+28y6C963n8VV1wi1lfy3M7OrovfsFTP7YJnruqOgpjVmtjRqL9t7NsJnRHl+z7z/MoAH4I1wGpJVwBFAFfAcMLdCtRwCnBItNwCvEi4a9W3gq+PgvVoDTBvW9g/Aomh5EXBNhf8t3wQOr8R7BrwLOAVYNtr7A3wIuI9weeUzgCfLXNcHgFS0fE1BXbMLt6vQe1b03y76v/Ac4cK1c6L/t8ly1TVs/T8BV5f7PRvhM6Isv2cHes9iLBdoKgt3f8Pdl0TLHcBLFLmGxzhTePGqG4GPVbCWs4BV7r433+LfY+7+B8L5zQqVen/OBW7y4AmgycwOKVdd7v6Ah+vHADxBOKtz2ZV4z0op2wXRRqrLzAy4APhFHM89khE+I8rye3agh8WYLrJUbmY2GzgZeDJqujzqRt5Q7qGeAg48YGbPmNllUdtB7v5GtPwmcFBlSgPCSSgL/wOPh/es1Psznn7v/orw12e/OWb2rJk9ambvrFBNxf7txst79k5go7uvKGgr+3s27DOiLL9nB3pYjDtmVg/cDXzF3XcAPwWOBOYBbxC6wJVwprufQrim+t+Y2bsKV3ro91bkOGwLp8A/B/hl1DRe3rMBlXx/SjGzbxDO6nxr1PQGcJi7nwxcAdxmZpPLXNa4+7cb5lMM/aOk7O9Zkc+IAXH+nh3oYTGuLrJkZmnCL8Gt7v4rAHff6O45d88DP6dC1yJ39/XRz03APVEdG/u7tdHPTZWojRBgS9x9Y1TjuHjPKP3+VPz3zsw+B3wE+MvoA4ZoiGdrtPwMYV7gmHLWNcK/3Xh4z1LAJ4A7+tvK/Z4V+4ygTL9nB3pYjOUCTWURjYVeD7zk7j8oaC8cY/w4sGz4Y8tQW52ZNfQvEyZIlzH04lWXAL8ud22RIX/tjYf3LFLq/VkMfDY6WuUMoL1gGCF2ZrYQ+Bpwjrt3FbS3mFkyWj6CcNGx1eWqK3reUv924+GCaH8BvOzu6/obyvmelfqMoFy/Z+WYxR/PN8IRA68S/iL4RgXrOJPQfXweWBrdPgTcDLwQtS8GDqlAbUcQjkR5Dlje/z4BU4HfAyuA3wHNFaitjnAp3saCtrK/Z4SwegPIEMaGLy31/hCOTrk2+p17AZhf5rpWEsay+3/PfhZte17077sUWAJ8tALvWcl/O+Ab0Xv2CnB2OeuK2v8d+NKwbcv2no3wGVGW3zOd7kNEREZ1oA9DiYjIGCgsRERkVAoLEREZlcJCRERGpbAQEZFRKSxExgEze4+Z/abSdYiUorAQEZFRKSxEdoOZXWxmT0XXLvgXM0uaWaeZ/TC6xsDvzawl2naemT1hg9eN6L/OwFFm9jsze87MlpjZkdHu683sLgvXmrg1+sauyLigsBAZIzM7FrgQeIe7zwNywF8SvkXe6u7HAY8Cfxc95Cbg6+5+IuEbtP3ttwLXuvtJwNsJ3xaGcBbRrxCuUXAE8I7YX5TIGKUqXYDIfuQs4FTg6eiP/kmEk7blGTy53C3Ar8ysEWhy90ej9huBX0bn2Jrp7vcAuHsPQLS/pzw675CFK7HNBv4r/pclMjqFhcjYGXCju181pNHsW8O229Nz6PQWLOfQ/08ZRzQMJTJ2vwfON7PpMHDt48MJ/4/Oj7b5NPBf7t4ObC+4GM5ngEc9XOFsnZl9LNpHtZnVlvVViOwB/eUiMkbu/qKZfZNwxcAE4aykfwPsBBZE6zYR5jUgnC76Z1EYrAY+H7V/BvgXM/tutI9PlvFliOwRnXVWZC+ZWae711e6DpE4aRhKRERGpZ6FiIiMSj0LEREZlcJCRERGpbAQEZFRKSxERGRUCgsRERnV/weFjOHCjavjIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('MSE')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmUnHW95/H3t/d9z9qddIcEQhYgIR2UCzggW3AhIMgmiDN40bky43JF8Y56lTMzBx2vqCMXROAKAUUEGbmCEpD9CpgQErJDE7J01k5v6X39zh9PdVLpdFLd6a6u7qrP65w6VfU8v6r6dp+kPv37/Z7n95i7IyIicixJsS5ARETGPoWFiIhEpLAQEZGIFBYiIhKRwkJERCJSWIiISEQKCxERiUhhIXIczGyrmXWaWUm/7W+bmZtZhZmVmdkTZrbfzBrNbJ2ZfS7UriLUrrnf7eqY/EAiEaTEugCRcewD4Frg/wKY2SlAVtj+ZcAaoBzoAE4BJvd7jwJ3745+qSLDo56FyPFbBnw27PmNwENhzxcDv3L3Fnfvdve33f1Po1qhyAhRWIgcvzeAPDObY2bJwDXAw/3232Vm15jZ9JhUKDJCFBYiw9PXu7gQ2AjsDNv3aeBV4DvAB2a22swW93v9fjNrCLvNGZWqRYZIcxYiw7MMeAWYweFDULh7PXAbcFtoIvxHwP8zs7KwZiWas5DxQD0LkWFw920EE90fA35/jHb7CcJiKlA0OtWJjByFhcjw3QR81N1bwjea2Q/MbL6ZpZhZLvBfgSp3r41JlSLDoLAQGSZ3f9/dVw6wKwt4EmgAthAcQntpvzYN/c6z+FqUyxU5LqaLH4mISCTqWYiISEQKCxERiUhhISIiESksREQkorg5Ka+kpMQrKipiXYaIyLjy1ltv7Xf3CZHaxU1YVFRUsHLlQEcviojI0ZjZtsG00zCUiIhEpLAQEZGIFBYiIhJR3MxZDKSrq4vq6mra29tjXUrUZWRkUFZWRmpqaqxLEZE4FNdhUV1dTW5uLhUVFZhZrMuJGnentraW6upqZsyYEetyRCQOxfUwVHt7O8XFxXEdFABmRnFxcUL0oEQkNuI6LIC4D4o+ifJzikhsxH1YRNLZ3cuexjY6u3tjXYqIyJiV8GHR686+pg6aO6JzZcuGhgb+9V//dciv+9jHPkZDQ0MUKhIRGbqED4v0lCSSk4zWztENi+7uY3/eM888Q0FBQVRqEhEZqrg+GmowzIystBRaOnqi8v633XYb77//PgsWLCA1NZWMjAwKCwvZtGkT7777Lpdddhk7duygvb2dL3/5y9x8883AoeVLmpubueSSSzj77LP561//SmlpKX/4wx/IzMyMSr0iIgNJmLD4/r+vZ8OuAwPu6+rppbO7l6z0FIYyTTx3ah7//Ml5x2xzxx13sG7dOlavXs1LL73Exz/+cdatW3fwENcHHniAoqIi2traWLx4MVdccQXFxcWHvcd7773Hb37zG375y19y1VVX8cQTT3D99dcPoVIRkeFJmLA4lqSkICJ6e53kpOgeVXTGGWccdi7Ez372M5588kkAduzYwXvvvXdEWMyYMYMFCxYAsGjRIrZu3RrVGkVE+kuYsDhWD6C311m/+wAlOWlMyY/u8E52dvbBxy+99BLPP/88r7/+OllZWZx77rkDniuRnp5+8HFycjJtbW1RrVFEpL+En+CGoGeRmZpMaxTmLXJzc2lqahpwX2NjI4WFhWRlZbFp0ybeeOONEf98EZGRkDA9i0iy0pKpbemk152kETzBrbi4mLPOOov58+eTmZnJpEmTDu5bsmQJ99xzD3PmzGH27Nl8+MMfHrHPFREZSebu0XtzsyXAT4Fk4D53v6Pf/nTgIWARUAtc7e5bzawC2AhsDjV9w92/eKzPqqys9P4XP9q4cSNz5swZVK2NbZ1sq21l5oQcstPHZ4YO5ecVEQEws7fcvTJSu6h9K5pZMnAXcCFQDawws6fcfUNYs5uAenefZWbXAD8Arg7te9/dF0Srvv6y0oJfRWtn97gNCxGRaInmnMUZQJW7b3H3TuBRYGm/NkuBB0OPHwfOtxgtcpSanER6SlLUzrcQERnPohkWpcCOsOfVoW0DtnH3bqAR6DtudIaZvW1mL5vZOQN9gJndbGYrzWxlTU3NsAvOSkuhtbOHaA7NiYiMR2P1aKjdwHR3Xwh8Dfi1meX1b+Tu97p7pbtXTpgwYdgfmpWeTHdvrxYVFBHpJ5phsROYFva8LLRtwDZmlgLkA7Xu3uHutQDu/hbwPnBSFGsFIDs0b9HSqaEoEZFw0QyLFcCJZjbDzNKAa4Cn+rV5Crgx9PhK4AV3dzObEJogx8xOAE4EtkSxViBsUcEorUArIjJeRS0sQnMQtwDPEhwG+5i7rzez283s0lCz+4FiM6siGG66LbT9I8A7ZraaYOL7i+5eF61a+5gZ2WkpI9qzON4lygF+8pOf0NraOmK1iIgcr6jOWbj7M+5+krvPdPf/Fdr2XXd/KvS43d0/7e6z3P0Md98S2v6Eu89z9wXufrq7/3s06wyXlZ5MR3cP3T0jM2+hsBCReKATCvrJPni+RQ95mcPP0vAlyi+88EImTpzIY489RkdHB5dffjnf//73aWlp4aqrrqK6upqenh6+853vsHfvXnbt2sV5551HSUkJL7744rBrERE5XokTFn+6DfasjdgsC+eEzh5Skw2Sk4/dePIpcMkdx2wSvkT58uXLefzxx/nb3/6Gu3PppZfyyiuvUFNTw9SpU3n66aeBYM2o/Px8fvzjH/Piiy9SUlIy6B9TRCQaxuqhszFjGMlm9Ebh6Nnly5ezfPlyFi5cyOmnn86mTZt47733OOWUU3juuef45je/yauvvkp+fv7If7iIyDAkTs8iQg8gXENjG/ubO5k3Je/gtS5GgrvzrW99iy984QtH7Fu1ahXPPPMM3/72tzn//PP57ne/O2KfKyIyXOpZDCArLQV3p61r+EdFhS9RfvHFF/PAAw/Q3NwMwM6dO9m3bx+7du0iKyuL66+/nltvvZVVq1Yd8VoRkVhKnJ7FEGSnBXMVLSOwqGD4EuWXXHIJ1113HWeeeSYAOTk5PPzww1RVVXHrrbeSlJREamoqd999NwA333wzS5YsYerUqZrgFpGYiuoS5aNpuEuU97d5TxPpKUlUlGRHbjxGaIlyERmqwS5RrmGoo8hKS6a1s1uLCoqIoLA4quz0ZLp7nQ4tKigiEv9hcbw9g/CLIY0H6gGJSDTFdVhkZGRQW1t7XF+k6SlJpCSNj4shuTu1tbVkZGTEuhQRiVNxfTRUWVkZ1dXVHO+FkeqaO9jX6zTnjf0v4YyMDMrKymJdhojEqbgOi9TUVGbMmHHcr7/n5fe540+bWPntCyjJSR/BykRExpe4HoYarsUVhQCs3Fof40pERGJLYXEM80vzSUtJ4q1tUb+UhojImKawOIb0lGROLc1n5Tb1LEQksSksIlhUUci6nY20j8A6USIi45XCIoLK8iK6epw1OxpiXYqISMwoLCJYVB6a5NZQlIgkMIVFBEXZacyckM1bCgsRSWAKi0GoLC/irW319PZqSQ0RSUwKi0FYVFFIY1sXVTXNsS5FRCQmFBaDsLiiCNDJeSKSuBQWg1BRnEVxdhordXKeiCQohcUgmBmLygs1yS0iCUthMUiVFYVsq21lX1N7rEsRERl1CotBqgzNW7yleQsRSUAKi0GaPzWf9JQknZwnIglJYTFIaSlJnFZWoLAQkYSksBiCRRWFrN/ZSFunFhUUkcSisBiCxRWFdPc6q7WooIgkGIXFEJw+PVhUUBdDEpFEo7AYgoKsNE6cmKN5CxFJOAqLIaqsKNSigiKScKIaFma2xMw2m1mVmd02wP50M/ttaP+bZlbRb/90M2s2s69Hs86hWFReRFN7N+/ua4p1KSIioyZqYWFmycBdwCXAXOBaM5vbr9lNQL27zwLuBH7Qb/+PgT9Fq8bjsbgidDEknZwnIgkkmj2LM4Aqd9/i7p3Ao8DSfm2WAg+GHj8OnG9mBmBmlwEfAOujWOOQTS/KoiQnXetEiUhCiWZYlAI7wp5Xh7YN2Mbdu4FGoNjMcoBvAt8/1geY2c1mttLMVtbU1IxY4RE+k8ryQq1AKyIJZaxOcH8PuNPdj3m1IXe/190r3b1ywoQJo1MZwST3jro29h7QooIikhiiGRY7gWlhz8tC2wZsY2YpQD5QC3wI+KGZbQW+AvyTmd0SxVqHpFIXQxKRBBPNsFgBnGhmM8wsDbgGeKpfm6eAG0OPrwRe8MA57l7h7hXAT4D/7e4/j2KtQzJvah4ZqUkaihKRhJESrTd29+5Qb+BZIBl4wN3Xm9ntwEp3fwq4H1hmZlVAHUGgjHmpycGigprkFpFEEbWwAHD3Z4Bn+m37btjjduDTEd7je1EpbpgqKwq55+UttHR0k50e1V+jiEjMjdUJ7jGvsqKInl5njRYVFJEEoLA4TqdPL8QMrRMlIglBYXGc8jNTOWlirsJCRBKCwmIYFlUUsmpbPT1aVFBE4pzCYhgWVxTS3NHN5j1aVFBE4pvCYhgqy4OT83QxJBGJdwqLYSgrzGRibrrmLUQk7ikshsHMqKwo1LIfIhL3FBbDVFlexM6GNnY3tsW6FBGRqFFYDFOlLoYkIglAYTFMc6bkkZmarHWiRCSuKSyGKTU5iQXTCrQCrYjENYXFCKisKGTDrgM0d3THuhQRkahQWIyAyooieh1Wb9eigiISnxQWI2Dh9ILQooIaihKR+KSwGAF5GanMnpSrSW4RiVsKixFSGVpUsLunN9aliIiMOIXFCFlcUURLZw+btKigiMQhhcUIWVQenJynoSgRiUcKixFSWpDJ5LwMLSooInFJYTFCzIxFFYWs3KojokQk/igsRtDi8kJ2N7azs0GLCopIfFFYtNbBY5+Fxp3DfqvKiuBiSOpdiEi8UVg0bIOqF+DBT8CBXcN6q5Mn55KVpkUFRST+KCymLoQbfg/NNfCr4QVGSnISC6cXsELLlYtInFFYAEw7A65/Apr3woOfhAO7j/utKsuL2LznAE3tXSNYoIhIbCks+kz/EFz/e2jaEwxJNe05rreprCik1+FtLSooInFEYRFu+oeCHsaB3cGQ1HEExsLphSQZOt9CROKKwqK/6R8OBcauYEiqae+QXp6TnsLJk/N0RJSIxBWFxUDKz4TrHw8Op33wE9C8b0gvr6woZPWOBi0qKCJxQ2FxNOV/B5/5HTRWB0NSQwiMyooiWjt72LhbiwqKSHxQWBxLxVmhwNgRDEkNMjAqQ4sK6mJIIhIvFBaRVJwN1z0GDdtDgVET8SVTCzKZmq9FBUUkfgwqLMzsy2aWZ4H7zWyVmV0U7eLGjBnnBIFRvy0IjJb9EV+yqKKIlVvrcPdRKFBEJLoG27P4L+5+ALgIKARuAO6I9CIzW2Jmm82sysxuG2B/upn9NrT/TTOrCG0/w8xWh25rzOzyQf9E0TLjHLjut1C/dVCBsbiikL0HOqiu16KCIjL+DTYsLHT/MWCZu68P2zbwC8ySgbuAS4C5wLVmNrdfs5uAenefBdwJ/CC0fR1Q6e4LgCXAL8wsZZC1Rs8J/wmuexTqtsCDlx4zMHQxJBGJJ4MNi7fMbDlBWDxrZrlApONCzwCq3H2Lu3cCjwJL+7VZCjwYevw4cL6Zmbu3unt3aHsGMHbGck44N+hh1L0PDy2FltoBm508OY+c9BRNcotIXBhsWNwE3AYsdvdWIBX4zxFeUwrsCHteHdo2YJtQODQCxQBm9iEzWw+sBb4YFh4HmdnNZrbSzFbW1ESeeB4xJ5wL1z4KtVVBYLQeGQjJScbC6QWs1KKCIhIHBhsWZwKb3b3BzK4Hvk3wxR417v6mu88DFgPfMrOMAdrc6+6V7l45YcKEaJZzpJnnwbW/gf3vBkNSAwRGZXkRm/c20dimRQVFZHwbbFjcDbSa2WnAPwLvAw9FeM1OYFrY87LQtgHbhOYk8oHDxnXcfSPQDMwfZK2jZ+ZHDwXGQ0cGRmVFIe7w9nb1LkRkfBtsWHR7cAzoUuDn7n4XkBvhNSuAE81shpmlAdcAT/Vr8xRwY+jxlcAL7u6h16QAmFk5cDKwdZC1jq5Z58O1v4aad48YklowrYDkJNMkt4iMe4MNiyYz+xbBIbNPm1kSwbzFUYXmGG4BngU2Ao+5+3ozu93MLg01ux8oNrMq4GsE8yIAZwNrzGw18CTwD+4e+eSGWJl1AVzza6jZBMsuOxgY2ekpzJmSywotKigi45wN5qQxM5sMXAescPdXzWw6cK67RxqKGjWVlZW+cuXK2Bbx3nPw6HUwcQ589g+QWcj3nlrPoyu2s/Z7F5OarBPmRWRsMbO33L0yUrtBfXu5+x7gESDfzD4BtI+loBgzTrwQrn4E9m2Ehy6DtnoqKwpp7+plw64Dsa5OROS4DXa5j6uAvwGfBq4C3jSzK6NZ2Lh10kVw9cOwbwMsu5zFk5IBXQxJRMa3wY6L/A+CcyxudPfPEpxw953olTXOnXQxXLUM9qxj0h+uYXZ+ry6GJCLj2mDDIsndw9fnrh3CaxPT7CVw9TLYs5Zf2P9i49ZqLSooIuPWYL/w/2xmz5rZ58zsc8DTwDPRKytOzL4ErnqIaR3vcWfn7VTvHtolWkVExorBTnDfCtwLnBq63evu34xmYXHj5I+x66J7mGcfkPW7q6BdE90iMv4MeijJ3Z9w96+Fbk9Gs6h4M/VDV3IrX6Wgfh08/CkFhoiMO8cMCzNrMrMDA9yazEzfeIOUnGTUl1/M/8z6Bux6Gx6+QoEhIuPKMcPC3XPdPW+AW667541WkfFgcXkh/1Z3Ci2X3ge7VsEjV0JHU6zLEhEZFB3RNEoWVQQXQ/pbxllw5QNQvRIeVmCIyPigsBglfYsKrthaB3OXhgJjBTzyaQWGiIx5CotRkpWWwrypeYfO5J53GVx5P+z4GzxyFXQ0x7ZAEZFjUFiMosryItbsaKCzO3RF2nmXwxX3wY434dcKDBEZuxQWo6iyopCO7l7W7wq7yOD8T8EVv4TtrweB0TJ2V2IXkcSlsBhFleXBJPcRF0OafwV86pfBHMbdfwfvvxCD6kREjk5hMYom5mUwrShz4IshnXIl/P0LkFkIyy6HZ/8HdHeMfpEiIgNQWIyyxeVFvLWtfuBFBSefAje/BIs/D6//HO47H2o2j3aJIiJHUFiMskUVhexv7mRbbevADVIz4eP/Atc+Cgd2wS/+E6x8ALRirYjEkMJilFWWFwGDuBjS7Evgv/4Vys+EP34VHv0MtNSOQoUiIkdSWIyyEyfmkJeRMriLIeVOhs88ARf/b6h6LjT5/WL0ixQR6UdhMcqSkozTywsHf5nVpCQ480vw+b9ARh4suwyWfxu6O6NbqIhIGIVFDCyuKKJqXzMNrUP4wp9yKtz8MlT+F/jr/w1Nfr8bvSJFRMIoLGJg0dHOt4gkLQs+cSdc82torIZffARW/psmv0Uk6hQWMXBaWQEpScaKrUMMiz4nfzyY/J7+IfjjV+C310PrIOZARESOk8IiBjLTkplXms9b24bxBZ83Ba5/Ei76n/Dus3D3WbDl5ZErUkQkjMIiRhaXF7KmupGO7p7jf5OkJPi7/wZ//xdIz4GHlsJz39Xkt4iMOIVFjFRWFNLZ3cu6nSNwedUppwWT34s+B//xU7j/QthfNfz3FREJUVjEyKK+k/MGc77FYKRlwSd/Alc/DA3b4BfnwFsPavJbREaEwiJGJuSmU16cNfjzLQZrzieDye+ySvj3/w6PfVaT3yIybAqLGKosL2LV0RYVHI68qXDDH+DC22Hzn4LJ7w9eGdnPEJGEorCIocqKQmpbOvlgf8vIv3lSEpz1Zfj8c8EQ1YOXwvPfg56ukf8sEYl7CosY6rsY0srjPd9iMKYuhC+8Aqd/Fl67M5j8rn0/ep8nInFJYRFDMyfkkJ+ZysrhnG8xGGnZcOnP4KplUPcB3HMOrFqmyW8RGbSohoWZLTGzzWZWZWa3DbA/3cx+G9r/pplVhLZfaGZvmdna0P1Ho1lnrCQlGZVDWVRwuOZeGkx+l54OT90Cv/sctI3SZ4vIuBa1sDCzZOAu4BJgLnCtmc3t1+wmoN7dZwF3Aj8Ibd8PfNLdTwFuBJZFq85YW1RRyJaaFmqbR+kSqvml8Nk/wAXfg01/hLvPhq2vjc5ni8i4Fc2exRlAlbtvcfdO4FFgab82S4EHQ48fB843M3P3t919V2j7eiDTzNKjWGvM9F0MaciLCg5HUjKc/VW4aTmkpMOvPgF/uV2T3yJyVNEMi1JgR9jz6tC2Adu4ezfQCBT3a3MFsMrdR+lP79F1alk+qck2umHRp3RRMPm98DPw6r/AAxdr8ltEBjSmJ7jNbB7B0NQXjrL/ZjNbaWYra2pqRre4EZKRmsz80vzRm7foLz0Hlt4Fn34QaquCZc9X3AedR7lGuIgkpGiGxU5gWtjzstC2AduYWQqQD9SGnpcBTwKfdfcB/9x193vdvdLdKydMmDDC5Y+exRVFrK1upL1rGIsKDte8y4LJ7ykL4Ol/hH+ZHVz7e+cqHTUlIlENixXAiWY2w8zSgGuAp/q1eYpgAhvgSuAFd3czKwCeBm5z9/+IYo1jwqLyQjp7elm3szG2heSXwef+CJ97GmZ/DFb/Bn55HtxzNrxxt5YNEUlgUQuL0BzELcCzwEbgMXdfb2a3m9mloWb3A8VmVgV8Deg7vPYWYBbwXTNbHbpNjFatsdZ35bzjvhjSSDKDirPhU7+Ar2+Gj/8YktPgz7cFvY3ffQ6qnofeGPaCRGTU2YivSxQjlZWVvnLlyliXcdzO+9FLzJyQzX03Lo51KQPbuz44ke+d30JbHeSVBRPjC66DwopYVycix8nM3nL3ykjtxvQEdyLpOzmvu6c31qUMbNI8uOQO+MdN8OlfwYTZ8PIP4aenBetOrX0cutpjXaWIRInCYow4d/ZEGlq7uOjOV3j6nd309o7RHl9KOsy7HG74PXxlLZz7T1D/ATxxUzBM9cytsHtNrKsUkRGmYagxwt1ZvmEvP3p2M+/ta+aU0nxuvXg255xYgpnFurxj6+2Fra8Ew1Qb/x16OmDyqcHihadcCZmFsa5QRI5isMNQCosxpqfXefLtndz53LvsbGjjzBOK+caS2SycPk6+cNvqgyGpVQ/BnncgOT24INPpN0DFR4Kl00VkzFBYjHMd3T38+s3t/PyFKmpbOrlo7iS+fvFsTpqUG+vSBm/3Gnj74WBSvL0RCsph4fXBpHh+WayrExEUFnGjuaObB177gHtf2UJrZzeXLyzjqxeeSFlhVqxLG7yu9mDRwlUPwQcvAwYzPxr0NmZ/LJgHEZGYUFjEmbqWTu5+qYoHX98GDp/58HS+dN4sSnLG2Rdt/TZY/Qi8/QgcqIbMIjj16iA4Js2LdXUiCUdhEad2NbTxs7+8x2Mrd5CZmsxN55zA358zg9yM1FiXNjS9PbDlJXh7GWx6Gno6YerpwTDVKVdCRn6sKxRJCAqLOFe1r5kfP7eZZ9buoTArlS+dN4vrP1xORmpyrEsbuta6YF5j1TLYtx5SMmHu0mBifPIpUDA9OLNcREacwiJBvFPdwP95djOvvrefqfkZfOWCk/jU6aWkJI/Do47cYdfbQW9j7ePQcSDYnp4fDFFNnh+Ex6T5MHEOpGbGtl6ROKCwSDD/UbWfH/55E2uqG5k5IZuvXzSbJfMnj/1zNI6mqw32rIO9a0P364L7rpZgvyVB8YlBgEwKC5HcyeqFiAyBwiIBuTvPrt/Lj5ZvpmpfM6eV5fONJSdz1qySWJc2Mnp7g7PF+4Kj775x+6E2WSVHBkjJSZCSFru6RcYwhUUC6+7p5fdv7+Snz7/HzoY2zppVzDcuPpnTphXEurToaKsPFjoM74ns2xicSQ6QlAoTTg4Lkfkw6RTI7n9RRpHEo7AQOrp7eOSN7fz8xSrqWjpZMm8yX7/4JGZNHEcn9h2vnu7gyn971wVnkvf1RJr3HmqTO/XIACmeGVyjXCRBKCzkoOaObu57dQu/fGULbV09XHF6GV+58CRKCxJwgri5pt88yFrY/y70dgf7UzKDyfO+8Jg8P+iVZBZqLkTiksJCjlDb3MG/vvQ+y17fBsANZ5bzD+fOpHi8ndg30ro7oGbT4QGyZy20Nxxqk5EPRScMfMueoCCRcUthIUe1s6GNnzz3Lk+sqiYrLYXPnzODz59zAjnpKbEubexwhwM7gwCpex/qthy6NWwHD7vuSFoOFM0YOEhyJmvxRBnTFBYSUdW+Jn707Lv8ef0eirLTuOW8WXzmw9NJT9GY/TF1d0LjjsMDpO9Wvw16uw61TcmAwr4g6Rco+WWaH5GYU1jIoK3e0cAP/7yJv75fS2lBJl88dyaXzJ88/tadGgt6uoM1rw4GyAeHP+47QguCo7QKKwbokcwIzlpPHmdLuMi4pLCQIXvtvf388NlNvFPdiBmcPr2QC+dO4oI5k5g1MSfW5Y1/vb3QtHuAHkkoUPpOOASw5CAwBhraKqzQeSMyYhQWclzcnQ27D/Dchr08v3Ev63YGS26cUJLNBXMnceHcSZw+vZDkJE3ojih3aN438NBW3QfQ0XiorSUFQ1hFMw8FSPHMsCBRj1AGT2EhI2JXQxt/2biX5Rv28saWWrp6nKLsND568kQumDOJj5xUQlaaJsajyh1aa0M9kLDJ9tr3g+ftYUGCQf60YCirOCxMimYGQZKaEaufQsYohYWMuKb2Ll5+t4bnNuzlxU37ONDeTVpKEmfPKuHCuZM4/+SJTMzTl9Goa63rFyBbDoVKW31YQ4O8UigOC5DweRItzJiQFBYSVV09vaz4oI7nNu7luQ17qa5vA2DBtAIuDA1XnTgxZ/wuZBgvWuvCJtn79Ura6g5vm1d65PxI8czgaK60cXRlRhkShYWMGndn894mnlsfzHOsqQ6GRcqLs7hgThAcleWF43PZ9HjWVn/4BHt4r6S19vC2uVPDDv+dEQRIYUXwOLMwJuXLyFBYSMzsaWzn+Y1BcPy1qpbOnl4KslL56OyJXDB3Eh85aYJOABzr2hqCFX5r3z+yZ9JSc3jbjPzQuSRoLv2vAAAN4klEQVShAAkPkrxSnUsyxiksZExo7ujm1dA8xwub99HQ2kVachJnziw+eFju5HzNc4wrHU3ByYf1H0D91iBM+h43bD+0zhYE55IUTD+yN1JYEdzSsmPyI8ghCgsZc7p7elm5rZ7nN+zluY172VbbCsCpZflcOGcSF8ydxMmTczXPMZ71dAfLpNR/EAqRrWGhsvXwQ4ABciYd2Rvpe5wzUWtujQKFhYxp7k7VvmaWh87neHt7sGhfWWEmF8yZxEVzJ7F4RhGpmueIH+7BPMkRQbIteH5gJxD2fZSadShI+g9xFUzXiYkjRGEh48q+pnZe2LiP5zbs5bWq/XR095KeksS8qXmcWlbAgmkFnFqWT0VxNkk6ITA+dXcEw1hH9EhC991th7fPKoG8KZA7Jbicbu7U0P2UQ9uzSrSQYwQKCxm3Wju7efW9/az4oI53qhtZu7ORtq4eAPIyUji1LAiO06YVcFpZgeY8EoF7cOGqurC5kabdYbc9wRnw9Ps+S0oJhroOBsqUgQMmIz9hh7wUFhI3unt6qappZs2OBtZUN7JmRwOb9zTR3Rv8252Ul35Y7+PU0gLys7QIX8Lp6QoCo2nPkUFyYNeh7eHXKemTkhmERl5Y76R/wORMjsvzTRQWEtfau3pYv+sA71Q38E4oQLbsP7QQ34ySbE4ry+fUsgJOm1bAvKl5ZKTqEE4BOluhec+RIRIeMgd2HznsBUEP5GCQTIHcSUHPJXtCcJ8zMbhlFIybnorCQhJOY1sXa6sbWVPdwJodQYjsOdAOQEqSMXtybhAeoSGsEyfm6ERBGZh7sObWQL2UvjBp2hOETvihwn2S0yB7IuRMGDhMsieGnk+A9LyYBsuYCAszWwL8FEgG7nP3O/rtTwceAhYBtcDV7r7VzIqBx4HFwK/c/ZZIn6WwkIHsPdAeGr461AM50B78585MTWZ+ad7B3sdpZflML8rSobsyeL29wbBW875gTqWlJrhv3hfcWkLbm2uCfd5z5HukZITCY2K/MOm7hYVN+shfKiDmYWFmycC7wIVANbACuNbdN4S1+QfgVHf/opldA1zu7lebWTawEJgPzFdYyEhxd7bWtvJOdQOrQ72PdTsb6egOLpNakJUazH+EhrBOnZbPxFxNoMsI6O0N1uM6IkwGelzDEZP1EBxOPFCYTFkAs5ccV1mDDYtorrlwBlDl7ltCBT0KLAU2hLVZCnwv9Phx4OdmZu7eArxmZrOiWJ8kIDNjRkk2M0qyWbqgFAgWRXx3bxNrdjQeDJG7XtpPT2gCvTArlenF2ZQXZVFenMX0oizKi7MpL85iYm66eiIyOElJkF0S3CbNO3bb3p5gfa6jBUvz3mDple2vB+1Oueq4w2KwohkWpcCOsOfVwIeO1sbdu82sESgG9g/mA8zsZuBmgOnTpw+3XklQqclJzJuaz7yp+Vz3oeDfUVtnD+t3NbKmupEtNc1sq23l7R31PL1298EQAchITWJ6URbTi4Lw6AuTiuJsSgszdVKhHJ+k5EM9h0h6uqC7PeoljevV3Nz9XuBeCIahYlyOxJHMtGQqK4qorCg6bHtXTy8769vYVtfK9toWttW2hh638lpVDe1dvQfbJicZUwsyKC/KZnpxVljPJAiWbC2mKCMhOXVUrtcezX+tO4FpYc/LQtsGalNtZilAPsFEt8iYlJqcREVJNhUl2cCEw/a5O/uaOoIAqW1he13rwTD509rd1Ld2Hda+JCftsCGt8CApzk7T8JaMKdEMixXAiWY2gyAUrgGu69fmKeBG4HXgSuAFj5djeSXhmBmT8jKYlJfBGTOKjth/oL2L7bV9AdLCtv3B/Ztbavl/q3cS/i8/Oy358HmS4iymFmQyNT+TKQUZ5GXopEMZXVELi9AcxC3AswSHzj7g7uvN7HZgpbs/BdwPLDOzKqCOIFAAMLOtQB6QZmaXAReFH0klMt7kZaQyvzSf+aX5R+xr7+qhur6N7XWhoa3aVrbXtfLeviZe2LSPzp7ew9rnpKcwJT+DyfkZBwOk735KfiZT8jM0zCUjSifliYxxPb3O3gPt7GpoY3djO7sb29jVENwHz9upaeo44nV5GSlMLQiCY0pBJlPygvupfc/zM3RWu4yJQ2dFZAQEE+WZTC3IPGqbzu7ewwJlV2MbexrbD4bKmupG6lo6j3hdUXYak/MymNrXI+nroeQHzyflp5OeokARhYVIXEhLSWJaURbTio6+0F17V08QII1t7A6FyK7GdvY0tlNd38aKrfU0tnUd8bqSnPRQmAQBUpKTRklOenDLTac4O40JuenqpcQ5hYVIgshITQ47kmtgLR3dB4e6dje2HxYqW2pa+GtVLU0dA6yFRDCP0hckxf0CpSQ7LbjPSackJ42c9BQd7TXOKCxE5KDs9BRmTcxh1sSjr0HU3tVDbUsn+5s62N/cd+s8dN/UwZaaFlZsrR9w6AsgPSXpYHD0hcrBgMkNtk/ISac4J52CzFRd8GoMUFiIyJBkpCZTWpBJ6THmUPp09/RS19JJTShIasPDpamDmuYOdje2s3ZnI7UtnYedHd8nJckoyj7UY5kQCpSCrFSKstIozE6jKDuNwqw0CrNSKchKI1nhMuIUFiISNSnJSUzMy2BiXuTFGHt7nYa2LmqbOw6GS1/vpfZgzyXotexv7ji4+GN/ZpCfGQRJQVbqwSApyk6jICuNouzUfs/TyM9MVcBEoLAQkTEhKdSDKMpO48RJuRHbt3X2UNfaSX1LJ/WtndS1BI/rWrto6Hve2snOhnbW7zpAbUsnnccImILMIEQKD4bLoedFB7enHnyen2DDYwoLERmXMtOSKU0b3HAYBMuxtHX1UNfSSUNr18EwCe67QkETBM7OhjbW7WykrvXoAZNkkJeZSl5GKnmZKcF9+OPMVPIyUsLaHL4vOy15XE3yKyxEJCGYGVlpKWSlpVBWOLjXuDutnT3Ut3ZS39J1WE+mPhQyTe1dHGjv5kBbF1v2N3OgrZsD7V20dg5woaMwyUlGbkbKuAkbhYWIyFGYGdnpKWSnDz5g+nT19NIUCpED7V0HQ2Tg58MLm4vmTuLbn5g7jJ80MoWFiEgUpCYnHZyDOR5DCZspgxyKGw6FhYjIGDTcsBlpuoyXiIhEpLAQEZGIFBYiIhKRwkJERCJSWIiISEQKCxERiUhhISIiESksREQkInM/cv348cjMaoBtw3iLEmD/CJUz3ul3cTj9Pg7R7+Jw8fD7KHf3CZEaxU1YDJeZrXT3yljXMRbod3E4/T4O0e/icIn0+9AwlIiIRKSwEBGRiBQWh9wb6wLGEP0uDqffxyH6XRwuYX4fmrMQEZGI1LMQEZGIFBYiIhJRwoeFmS0xs81mVmVmt8W6nlgys2lm9qKZbTCz9Wb25VjXFGtmlmxmb5vZH2NdS6yZWYGZPW5mm8xso5mdGeuaYsnMvhr6f7LOzH5jZhmxrimaEjoszCwZuAu4BJgLXGtm0b2Q7djWDfyju88FPgx8KcF/HwBfBjbGuogx4qfAn939ZOA0Evj3YmalwH8HKt19PpAMXBPbqqIrocMCOAOocvct7t4JPAosjXFNMePuu919VehxE8GXQWlsq4odMysDPg7cF+taYs3M8oGPAPcDuHunuzfEtqqYSwEyzSwFyAJ2xbieqEr0sCgFdoQ9ryaBvxzDmVkFsBB4M7aVxNRPgG8AvbEuZAyYAdQA/xYalrvPzLJjXVSsuPtO4EfAdmA30Ojuy2NbVXQleljIAMwsB3gC+Iq7H4h1PbFgZp8A9rn7W7GuZYxIAU4H7nb3hUALkLBzfGZWSDAKMQOYCmSb2fWxrSq6Ej0sdgLTwp6XhbYlLDNLJQiKR9z997GuJ4bOAi41s60Ew5MfNbOHY1tSTFUD1e7e19N8nCA8EtUFwAfuXuPuXcDvgb+LcU1RlehhsQI40cxmmFkawQTVUzGuKWbMzAjGpDe6+49jXU8sufu33L3M3SsI/l284O5x/Zfjsbj7HmCHmc0ObTof2BDDkmJtO/BhM8sK/b85nzif8E+JdQGx5O7dZnYL8CzB0QwPuPv6GJcVS2cBNwBrzWx1aNs/ufszMaxJxo7/BjwS+sNqC/CfY1xPzLj7m2b2OLCK4CjCt4nzpT+03IeIiESU6MNQIiIyCAoLERGJSGEhIiIRKSxERCQihYWIiESksBAZA8zsXK1sK2OZwkJERCJSWIgMgZldb2Z/M7PVZvaL0PUums3sztC1Df5iZhNCbReY2Rtm9o6ZPRlaTwgzm2Vmz5vZGjNbZWYzQ2+fE3a9iEdCZwaLjAkKC5FBMrM5wNXAWe6+AOgBPgNkAyvdfR7wMvDPoZc8BHzT3U8F1oZtfwS4y91PI1hPaHdo+0LgKwTXVjmB4Ix6kTEhoZf7EBmi84FFwIrQH/2ZwD6CJcx/G2rzMPD70PUfCtz95dD2B4HfmVkuUOruTwK4eztA6P3+5u7VoeergQrgtej/WCKRKSxEBs+AB939W4dtNPtOv3bHu4ZOR9jjHvT/U8YQDUOJDN5fgCvNbCKAmRWZWTnB/6MrQ22uA15z90ag3szOCW2/AXg5dAXCajO7LPQe6WaWNao/hchx0F8uIoPk7hvM7NvAcjNLArqALxFcCOiM0L59BPMaADcC94TCIHyV1huAX5jZ7aH3+PQo/hgix0WrzooMk5k1u3tOrOsQiSYNQ4mISETqWYiISETqWYiISEQKCxERiUhhISIiESksREQkIoWFiIhE9P8BxUA3mrTW+P0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'][:10])\n",
    "plt.plot(history.history['val_loss'][:10])\n",
    "plt.title('MSE')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('10mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['PSNRLoss'])\n",
    "plt.plot(history.history['val_PSNRLoss'])\n",
    "plt.title('PNSR loss')\n",
    "plt.ylabel('PSNR')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('psnr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('1608Stable_adam_checkpoint.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
